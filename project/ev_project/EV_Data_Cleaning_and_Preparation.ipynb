{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "intro",
            "metadata": {},
            "source": [
                "# EV Charging Data Cleaning & Preparation (v2 - Robust Merge)\n",
                "\n",
                "**Goal:** Prepare a clean dataset for Neural Network modeling.\n",
                "**Key Improvement:** Correctly merges Session data with Weather data using a Left Join on Date, ensuring no data loss."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "load_data",
            "metadata": {},
            "source": [
                "## 1. Load Data\n",
                "Reading the raw EV session data and the weather data."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load_code",
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import os\n",
                "\n",
                "pd.set_option('display.max_columns', None)\n",
                "\n",
                "# File Paths\n",
                "SESSION_PATH = '../../data/trondheim/Dataset 1_EV charging reports.csv'\n",
                "WEATHER_PATH = '../../data/trondheim/Norway_Trondheim_ExactLoc_Weather.csv'\n",
                "OUT_FILE = 'data/ev_sessions_clean.csv'\n",
                "\n",
                "# 1. Load Sessions\n",
                "# Note: European format (semicolon sep, comma decimal)\n",
                "df_sessions = pd.read_csv(SESSION_PATH, sep=';', decimal=',')\n",
                "print(f\"Sessions Loaded: {df_sessions.shape}\")\n",
                "\n",
                "# 2. Load Weather\n",
                "# Note: Standard csv\n",
                "df_weather = pd.read_csv(WEATHER_PATH, low_memory=False)\n",
                "print(f\"Weather Loaded: {df_weather.shape}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "preprocess_dates",
            "metadata": {},
            "source": [
                "## 2. Preprocessing & Merging\n",
                "We need to create a common `date` column to join on."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "merge_logic",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- PROCESS SESSIONS ---\n",
                "# Parse start time to get the Date\n",
                "df_sessions['Start_plugin_dt'] = pd.to_datetime(df_sessions['Start_plugin'], dayfirst=True, errors='coerce')\n",
                "df_sessions['date'] = df_sessions['Start_plugin_dt'].dt.date\n",
                "\n",
                "# Drop invalid dates immediately\n",
                "df_sessions = df_sessions.dropna(subset=['Start_plugin_dt', 'date']).copy()\n",
                "\n",
                "# --- PROCESS WEATHER ---\n",
                "# Parse weather date\n",
                "df_weather['weather_dt'] = pd.to_datetime(df_weather['datetime'], errors='coerce')\n",
                "df_weather['date'] = df_weather['weather_dt'].dt.date\n",
                "\n",
                "# Select relevant weather columns\n",
                "weather_cols = ['date', 'temp', 'precip', 'clouds', 'solar_rad', 'wind_spd']\n",
                "# intersection with available columns to be safe\n",
                "available_weather_cols = [c for c in weather_cols if c in df_weather.columns]\n",
                "df_weather_clean = df_weather[available_weather_cols].copy()\n",
                "\n",
                "# Handle duplicates in weather (if any) by taking the mean or first - usually daily data is unique per day\n",
                "df_weather_clean = df_weather_clean.groupby('date').first().reset_index()\n",
                "\n",
                "# --- MERGE ---\n",
                "# Left Join: Keep all sessions, attach weather where possible\n",
                "df_merged = pd.merge(df_sessions, df_weather_clean, on='date', how='left')\n",
                "\n",
                "print(f\"Merged Shape: {df_merged.shape}\")\n",
                "print(f\"Missing Weather Rows: {df_merged['temp'].isna().sum()}\")\n",
                "\n",
                "# Sanity Check\n",
                "assert len(df_sessions) == len(df_merged), \"Error: Row count changed during merge!\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "clean_cols",
            "metadata": {},
            "source": [
                "## 3. Cleaning & Feature Engineering\n",
                "Fixing timestamps, durations, and creating the `is_short_session` target."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "feature_eng",
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Parse End Time\n",
                "df_merged['End_plugout_dt'] = pd.to_datetime(df_merged['End_plugout'], dayfirst=True, errors='coerce')\n",
                "\n",
                "# 2. Recompute Duration (Validation)\n",
                "df_merged['Duration_check'] = (df_merged['End_plugout_dt'] - df_merged['Start_plugin_dt']).dt.total_seconds() / 3600.0\n",
                "\n",
                "# Use recomputed duration if original is weird, but mostly trust recomputed\n",
                "df_merged['Duration_hours'] = df_merged['Duration_check']\n",
                "\n",
                "# 3. Filters (Physical possibilities)\n",
                "# - Remove negative/zero duration\n",
                "# - Remove near-zero duration (< 0.05h is likely error/testing)\n",
                "# - Remove El_kWh <= 0\n",
                "mask_valid = (\n",
                "    (df_merged['Duration_hours'] > 0.05) & \n",
                "    (df_merged['El_kWh'] > 0) &\n",
                "    (df_merged['Duration_hours'] < 240)  # Cap at 10 days (extreme outliers)\n",
                ")\n",
                "df_clean = df_merged[mask_valid].copy()\n",
                "\n",
                "print(f\"Rows dropped: {len(df_merged) - len(df_clean)}\")\n",
                "print(f\"Final Shape: {df_clean.shape}\")\n",
                "\n",
                "# 4. Feature Engineering\n",
                "# Cyclical time features\n",
                "df_clean['hour'] = df_clean['Start_plugin_dt'].dt.hour\n",
                "df_clean['hour_sin'] = np.sin(2 * np.pi * df_clean['hour'] / 24)\n",
                "df_clean['hour_cos'] = np.cos(2 * np.pi * df_clean['hour'] / 24)\n",
                "\n",
                "# Day of week\n",
                "df_clean['weekday'] = df_clean['Start_plugin_dt'].dt.dayofweek\n",
                "\n",
                "# 5. Target Creation\n",
                "# Binary Classification Target: is_short_session\n",
                "# 1 = Short (< 24h), 0 = Long (>= 24h)\n",
                "df_clean['is_short_session'] = (df_clean['Duration_hours'] < 24).astype(int)\n",
                "\n",
                "print(\"Class Distribution:\")\n",
                "print(df_clean['is_short_session'].value_counts(normalize=True))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "save",
            "metadata": {},
            "source": [
                "## 4. Save\n",
                "Saving to `data/ev_sessions_clean.csv`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "export",
            "metadata": {},
            "outputs": [],
            "source": [
                "os.makedirs('data', exist_ok=True)\n",
                "df_clean.to_csv(OUT_FILE, index=False)\n",
                "print(f\"Saved to {OUT_FILE}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}