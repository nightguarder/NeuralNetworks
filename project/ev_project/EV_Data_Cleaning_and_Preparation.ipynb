{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# EV Charging Data Cleaning & Preparation (v2 - Robust Merge)\n",
    "\n",
    "**Goal:** Prepare a clean dataset for Neural Network modeling.\n",
    "**Key Improvement:** Correctly merges Session data with Weather data using a Left Join on Date, ensuring no data loss."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "load_data",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "Reading the raw EV session data and the weather data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "load_code",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions Loaded: (6878, 15)\n",
      "Weather Loaded: (427, 36)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# File Paths\n",
    "SESSION_PATH = '../../data/trondheim/Dataset 1_EV charging reports.csv'\n",
    "WEATHER_PATH = '../../data/trondheim/Norway_Trondheim_ExactLoc_Weather.csv'\n",
    "OUT_FILE = 'data/ev_sessions_clean.csv'\n",
    "\n",
    "# 1. Load Sessions\n",
    "# Note: European format (semicolon sep, comma decimal)\n",
    "df_sessions = pd.read_csv(SESSION_PATH, sep=';', decimal=',')\n",
    "print(f\"Sessions Loaded: {df_sessions.shape}\")\n",
    "\n",
    "# 2. Load Weather\n",
    "# Note: Standard csv\n",
    "df_weather = pd.read_csv(WEATHER_PATH, low_memory=False)\n",
    "print(f\"Weather Loaded: {df_weather.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preprocess_dates",
   "metadata": {},
   "source": [
    "## 2. Preprocessing & Merging\n",
    "We need to create a common `date` column to join on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "merge_logic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Shape: (6878, 22)\n",
      "Missing Weather Rows: 0\n"
     ]
    }
   ],
   "source": [
    "# --- PROCESS SESSIONS ---\n",
    "# Parse start time to get the Date\n",
    "df_sessions['Start_plugin_dt'] = pd.to_datetime(df_sessions['Start_plugin'], dayfirst=True, errors='coerce')\n",
    "df_sessions['date'] = df_sessions['Start_plugin_dt'].dt.date\n",
    "\n",
    "# Drop invalid dates immediately\n",
    "df_sessions = df_sessions.dropna(subset=['Start_plugin_dt', 'date']).copy()\n",
    "\n",
    "# --- PROCESS WEATHER ---\n",
    "# Parse weather date\n",
    "df_weather['weather_dt'] = pd.to_datetime(df_weather['datetime'], errors='coerce')\n",
    "df_weather['date'] = df_weather['weather_dt'].dt.date\n",
    "\n",
    "# Select relevant weather columns\n",
    "weather_cols = ['date', 'temp', 'precip', 'clouds', 'solar_rad', 'wind_spd']\n",
    "# intersection with available columns to be safe\n",
    "available_weather_cols = [c for c in weather_cols if c in df_weather.columns]\n",
    "df_weather_clean = df_weather[available_weather_cols].copy()\n",
    "\n",
    "# Handle duplicates in weather (if any) by taking the mean or first - usually daily data is unique per day\n",
    "df_weather_clean = df_weather_clean.groupby('date').first().reset_index()\n",
    "\n",
    "# --- MERGE ---\n",
    "# Left Join: Keep all sessions, attach weather where possible\n",
    "df_merged = pd.merge(df_sessions, df_weather_clean, on='date', how='left')\n",
    "\n",
    "print(f\"Merged Shape: {df_merged.shape}\")\n",
    "print(f\"Missing Weather Rows: {df_merged['temp'].isna().sum()}\")\n",
    "\n",
    "# Sanity Check\n",
    "assert len(df_sessions) == len(df_merged), \"Error: Row count changed during merge!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean_cols",
   "metadata": {},
   "source": [
    "## 3. Cleaning & Feature Engineering\n",
    "Fixing timestamps, durations, and creating the `is_short_session` target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feature_eng",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows dropped: 133\n",
      "Final Shape: (6745, 24)\n",
      "Class Distribution:\n",
      "is_short_session\n",
      "1    0.932394\n",
      "0    0.067606\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 1. Parse End Time\n",
    "df_merged['End_plugout_dt'] = pd.to_datetime(df_merged['End_plugout'], dayfirst=True, errors='coerce')\n",
    "\n",
    "# 2. Recompute Duration (Validation)\n",
    "df_merged['Duration_check'] = (df_merged['End_plugout_dt'] - df_merged['Start_plugin_dt']).dt.total_seconds() / 3600.0\n",
    "\n",
    "# Use recomputed duration if original is weird, but mostly trust recomputed\n",
    "df_merged['Duration_hours'] = df_merged['Duration_check']\n",
    "\n",
    "# 3. Filters (Physical possibilities)\n",
    "# - Remove negative/zero duration\n",
    "# - Remove near-zero duration (< 0.05h is likely error/testing)\n",
    "# - Remove El_kWh <= 0\n",
    "mask_valid = (\n",
    "    (df_merged['Duration_hours'] > 0.05) & \n",
    "    (df_merged['El_kWh'] > 0) &\n",
    "    (df_merged['Duration_hours'] < 240)  # Cap at 10 days (extreme outliers)\n",
    " )\n",
    "df_clean = df_merged[mask_valid].copy()\n",
    "\n",
    "print(f\"Rows dropped: {len(df_merged) - len(df_clean)}\")\n",
    "print(f\"Final Shape: {df_clean.shape}\")\n",
    "\n",
    "# 4. Weather gap handling for flag creation\n",
    "df_clean['temp_filled'] = df_clean['temp'].fillna(df_clean['temp'].median())\n",
    "df_clean['precip_filled'] = df_clean['precip'].fillna(df_clean['precip'].median())\n",
    "df_clean['clouds_filled'] = df_clean['clouds'].fillna(df_clean['clouds'].median())\n",
    "df_clean['solar_rad_filled'] = df_clean['solar_rad'].fillna(df_clean['solar_rad'].median())\n",
    "\n",
    "# 5. Feature Engineering\n",
    "# Cyclical time features\n",
    "df_clean['hour'] = df_clean['Start_plugin_dt'].dt.hour\n",
    "df_clean['hour_sin'] = np.sin(2 * np.pi * df_clean['hour'] / 24)\n",
    "df_clean['hour_cos'] = np.cos(2 * np.pi * df_clean['hour'] / 24)\n",
    "\n",
    "# Day of week\n",
    "df_clean['weekday'] = df_clean['Start_plugin_dt'].dt.dayofweek\n",
    "\n",
    "# Weather-derived flags (simple buckets)\n",
    "df_clean['is_rainy'] = (df_clean['precip_filled'] >= 1.0).astype(int)\n",
    "df_clean['is_overcast'] = (df_clean['clouds_filled'] >= 80).astype(int)\n",
    "df_clean['is_sunny'] = (\n",
    "    (df_clean['clouds_filled'] <= 20)\n",
    "    & (df_clean['precip_filled'] < 0.2)\n",
    "    & (df_clean['solar_rad_filled'] >= df_clean['solar_rad_filled'].median())\n",
    ").astype(int)\n",
    "\n",
    "# 6. Target Creation\n",
    "# Binary Classification Target: is_short_session\n",
    "# 1 = Short (< 24h), 0 = Long (>= 24h)\n",
    "df_clean['is_short_session'] = (df_clean['Duration_hours'] < 24).astype(int)\n",
    "\n",
    "print(\"Class Distribution:\")\n",
    "print(df_clean['is_short_session'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411121b7",
   "metadata": {},
   "source": [
    "### Weather Flags Added\n",
    "- Added simple categorical weather flags to capture conditions without leaking outcomes:\n",
    "  - `is_rainy` = precip ≥ 1.0\n",
    "  - `is_overcast` = clouds ≥ 80\n",
    "  - `is_sunny` = low clouds (≤20), low precip (<0.2), and above-median solar radiation\n",
    "- Weather inputs are median-filled before flagging to avoid losing rows with missing weather."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "save",
   "metadata": {},
   "source": [
    "## 4. Save\n",
    "Saving to `data/ev_sessions_clean.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "export",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to data/ev_sessions_clean.csv\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('data', exist_ok=True)\n",
    "df_clean.to_csv(OUT_FILE, index=False)\n",
    "print(f\"Saved to {OUT_FILE}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
