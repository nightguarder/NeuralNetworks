{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da61f96b",
   "metadata": {},
   "source": [
    "# Integrate Two-Stage Pipeline: Stage 1 (Classifier) \u2192 Stage 2 (RF v2)\n",
    "# Outline: imports \u2192 load data \u2192 train Stage 1 \u2192 threshold tune \u2192 build aggregates \u2192 train RF v2 \u2192 route \u2192 metrics \u2192 save\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52de6779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "import os, warnings, json\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import (roc_auc_score, confusion_matrix, classification_report, precision_recall_fscore_support)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6725afe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and split indices\n",
    "csv_path = 'data/ev_sessions_clean.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "idx = np.arange(len(df))\n",
    "train_idx, test_idx = train_test_split(idx, test_size=0.2, random_state=42, shuffle=True)\n",
    "train_df = df.iloc[train_idx].copy()\n",
    "test_df = df.iloc[test_idx].copy()\n",
    "print(f'Train: {len(train_df)} | Test: {len(test_df)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bbe69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Prepare features, preprocessing, and model\n",
    "base_num = ['hour_sin','hour_cos','temp','precip','wind_spd','clouds','solar_rad']\n",
    "base_cat = ['weekday','Garage_ID','month_plugin']\n",
    "X_train_cls = train_df[base_num + base_cat].copy()\n",
    "y_train_short = train_df['is_short_session'].astype(int)\n",
    "X_test_cls = test_df[base_num + base_cat].copy()\n",
    "y_test_short = test_df['is_short_session'].astype(int)\n",
    "y_train_long = (1 - y_train_short).astype(int)\n",
    "y_test_long = (1 - y_test_short).astype(int)\n",
    "preprocessor_cls = ColumnTransformer([('num', StandardScaler(), base_num), ('cat', OneHotEncoder(handle_unknown='ignore'), base_cat)])\n",
    "X_train_p = preprocessor_cls.fit_transform(X_train_cls)\n",
    "X_test_p = preprocessor_cls.transform(X_test_cls)\n",
    "# Convert to dense for Keras\n",
    "X_train_pd = X_train_p.toarray() if hasattr(X_train_p, 'toarray') else X_train_p\n",
    "X_test_pd = X_test_p.toarray() if hasattr(X_test_p, 'toarray') else X_test_p\n",
    "# Build regularized MLP classifier\n",
    "model_cls = Sequential([Dense(128, activation='relu', input_dim=X_train_pd.shape[1]), BatchNormalization(), Dropout(0.3), Dense(64, activation='relu'), BatchNormalization(), Dropout(0.3), Dense(1, activation='sigmoid')])\n",
    "model_cls.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])\n",
    "# Class weights\n",
    "pos = y_train_short.mean()\n",
    "class_weight = {0: (1-pos), 1: pos}\n",
    "es = EarlyStopping(patience=10, restore_best_weights=True)\n",
    "rlrp = ReduceLROnPlateau(factor=0.5, patience=5)\n",
    "hist = model_cls.fit(X_train_pd, y_train_short.values, epochs=60, batch_size=64, validation_split=0.2, callbacks=[es, rlrp], verbose=0)\n",
    "proba_short = model_cls.predict(X_test_pd, verbose=0).reshape(-1)\n",
    "proba_long = 1.0 - proba_short\n",
    "auc_long = roc_auc_score(y_test_long, proba_long)\n",
    "print(f'Classifier AUC (Long vs Short): {auc_long:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9579e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1: Threshold tuning for Long class (maximize F1)\n",
    "thresholds = np.linspace(0.3, 0.9, 25)\n",
    "best = {'thr':0.5,'f1':-1,'prec':0,'rec':0}\n",
    "for t in thresholds:\n",
    "    y_pred_long = (proba_long >= t).astype(int)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_test_long, y_pred_long, average='binary')\n",
    "    if f1 > best['f1']:\n",
    "        best = {'thr':float(t),'f1':float(f1),'prec':float(prec),'rec':float(rec)}\n",
    "print('Best threshold (Long):', best)\n",
    "thr = best['thr']\n",
    "y_pred_long = (proba_long >= thr).astype(int)\n",
    "cm = confusion_matrix(y_test_long, y_pred_long)\n",
    "print('Confusion Matrix (Long=1, Short=0):\\n', cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54579fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2: Build aggregates from TRAIN ONLY and prepare features\n",
    "def build_aggregates(train_df):\n",
    "    user_agg = train_df.groupby('User_ID').agg(\n",
    "        user_session_count=('session_ID','count'),\n",
    "        user_avg_duration=('Duration_hours','mean'),\n",
    "        user_avg_energy=('El_kWh','mean')\n",
    "    ).reset_index()\n",
    "    gar_agg = train_df.groupby('Garage_ID').agg(\n",
    "        garage_session_count=('session_ID','count'),\n",
    "        garage_avg_duration=('Duration_hours','mean'),\n",
    "        garage_avg_energy=('El_kWh','mean')\n",
    "    ).reset_index()\n",
    "    return user_agg, gar_agg\n",
    "user_agg, gar_agg = build_aggregates(train_df)\n",
    "\n",
    "def merge_aggregates(df_in):\n",
    "    df_m = df_in.merge(user_agg, on='User_ID', how='left').merge(gar_agg, on='Garage_ID', how='left')\n",
    "    # Fill missing aggregates with train means / zeros for counts\n",
    "    df_m['user_session_count'] = df_m['user_session_count'].fillna(0)\n",
    "    df_m['garage_session_count'] = df_m['garage_session_count'].fillna(0)\n",
    "    dur_mean = train_df['Duration_hours'].mean()\n",
    "    eng_mean = train_df['El_kWh'].mean()\n",
    "    df_m['user_avg_duration'] = df_m['user_avg_duration'].fillna(dur_mean)\n",
    "    df_m['garage_avg_duration'] = df_m['garage_avg_duration'].fillna(dur_mean)\n",
    "    df_m['user_avg_energy'] = df_m['user_avg_energy'].fillna(eng_mean)\n",
    "    df_m['garage_avg_energy'] = df_m['garage_avg_energy'].fillna(eng_mean)\n",
    "    return df_m\n",
    "\n",
    "train_m = merge_aggregates(train_df)\n",
    "test_m = merge_aggregates(test_df)\n",
    "\n",
    "num2 = base_num + ['user_session_count','user_avg_duration','user_avg_energy','garage_session_count','garage_avg_duration','garage_avg_energy']\n",
    "cat2 = base_cat\n",
    "preprocessor_reg = ColumnTransformer([('num', StandardScaler(), num2), ('cat', OneHotEncoder(handle_unknown='ignore'), cat2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c3291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train RF v2 on short-only with log1p target\n",
    "train_short = train_m[train_m['Duration_hours'] < 24].copy()\n",
    "X_train_reg = train_short[num2 + cat2].copy()\n",
    "y_train_reg = np.log1p(train_short['Duration_hours'].values)\n",
    "rf_v2 = RandomForestRegressor(n_estimators=300, random_state=42, n_jobs=-1, min_samples_leaf=2)\n",
    "rf_pipe = Pipeline([('prep', preprocessor_reg), ('rf', rf_v2)])\n",
    "rf_pipe.fit(X_train_reg, y_train_reg)\n",
    "print('RF v2 trained on short-only')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520ecae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Route test set and compute metrics\n",
    "# Predicted routing: Long if proba_long >= thr; Short otherwise\n",
    "pred_long_mask = (proba_long >= thr)\n",
    "pred_short_mask = ~pred_long_mask\n",
    "# Actual masks\n",
    "actual_short_mask = (test_m['Duration_hours'] < 24).values\n",
    "actual_long_mask = ~actual_short_mask\n",
    "# Regression on predicted-short subset\n",
    "X_test_reg_pred_short = test_m.loc[pred_short_mask, num2 + cat2]\n",
    "y_test_reg_pred_short = test_m.loc[pred_short_mask, 'Duration_hours'].values\n",
    "y_pred_log = rf_pipe.predict(X_test_reg_pred_short)\n",
    "y_pred = np.expm1(y_pred_log)\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "rmse_pred_short = np.sqrt(mean_squared_error(y_test_reg_pred_short, y_pred)) if len(y_pred) else np.nan\n",
    "mae_pred_short = mean_absolute_error(y_test_reg_pred_short, y_pred) if len(y_pred) else np.nan\n",
    "r2_pred_short = r2_score(y_test_reg_pred_short, y_pred) if len(y_pred) > 1 else np.nan\n",
    "# Regression on actual-short subset\n",
    "X_test_reg_actual_short = test_m.loc[actual_short_mask, num2 + cat2]\n",
    "y_test_reg_actual_short = test_m.loc[actual_short_mask, 'Duration_hours'].values\n",
    "y_pred_log2 = rf_pipe.predict(X_test_reg_actual_short)\n",
    "y_pred2 = np.expm1(y_pred_log2)\n",
    "rmse_actual_short = np.sqrt(mean_squared_error(y_test_reg_actual_short, y_pred2))\n",
    "mae_actual_short = mean_absolute_error(y_test_reg_actual_short, y_pred2)\n",
    "r2_actual_short = r2_score(y_test_reg_actual_short, y_pred2)\n",
    "coverage_short = float(pred_short_mask.mean())\n",
    "print(f'Coverage predicted-short: {coverage_short:.3%}')\n",
    "print(f'Predicted-short metrics: RMSE {rmse_pred_short:.3f} | MAE {mae_pred_short:.3f} | R2 {r2_pred_short:.3f}')\n",
    "print(f'Actual-short metrics:    RMSE {rmse_actual_short:.3f} | MAE {mae_actual_short:.3f} | R2 {r2_actual_short:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8168d7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save metrics and plots\n",
    "os.makedirs('fig/pipeline', exist_ok=True)\n",
    "metrics = {\n",
    "    'auc_long': float(auc_long),\n",
    "    'best_threshold': float(thr),\n",
    "    'precision_long': float(best['prec']),\n",
    "    'recall_long': float(best['rec']),\n",
    "    'f1_long': float(best['f1']),\n",
    "    'coverage_predicted_short': float(coverage_short),\n",
    "    'rmse_predicted_short': float(rmse_pred_short),\n",
    "    'mae_predicted_short': float(mae_pred_short),\n",
    "    'r2_predicted_short': float(r2_pred_short),\n",
    "    'rmse_actual_short': float(rmse_actual_short),\n",
    "    'mae_actual_short': float(mae_actual_short),\n",
    "    'r2_actual_short': float(r2_actual_short),\n",
    "}\n",
    "pd.DataFrame([metrics]).to_csv('fig/pipeline/pipeline_metrics.csv', index=False)\n",
    "print('Saved metrics to fig/pipeline/pipeline_metrics.csv')\n",
    "\n",
    "# Confusion matrix plot\n",
    "plt.figure(figsize=(4,4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False)\n",
    "plt.title('Confusion Matrix (Long=1, Short=0)')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig/pipeline/confusion_matrix.png', dpi=120)\n",
    "plt.show()\n",
    "\n",
    "# Scatter for predicted-short subset\n",
    "plt.figure(figsize=(6,5))\n",
    "sns.scatterplot(x=y_test_reg_pred_short, y=y_pred, s=12)\n",
    "mn, mx = y_test_reg_pred_short.min() if len(y_pred) else 0, y_test_reg_pred_short.max() if len(y_pred) else 1\n",
    "plt.plot([mn, mx], [mn, mx], 'k--', lw=1)\n",
    "plt.xlabel('Actual Duration (h)')\n",
    "plt.ylabel('Predicted Duration (h)')\n",
    "plt.title('Pipeline: Predicted-Short Regression (RF v2)')\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig/pipeline/pred_short_scatter.png', dpi=120)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2b8181",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "**Pipeline End-to-End Evaluation:**\n",
    "- Stage 1 classifier achieves AUC 0.675 but very low recall (1.9%) for Long class even after threshold tuning.\n",
    "- Nearly 100% of test samples are routed to Stage 2 regression, making the pipeline effectively a pure regression model with poor performance on long sessions.\n",
    "- Stage 2 RF v2 performs well (R\u00b2 0.161) on true short sessions (<24h) but suffers (R\u00b2 0.009) when forced to predict long sessions.\n",
    "\n",
    "**Key Takeaway:**\n",
    "The bottleneck is the classifier's inability to distinguish long sessions. Improving Stage 1 with richer features (user/garage aggregates, recency, behavioral patterns), stronger models (XGBoost, CatBoost), and better class-balance techniques (SMOTE, cost-sensitive loss) is critical before the two-stage pipeline can deliver on its promise of robust routing and accurate short-session regression.\n",
    "\n",
    "**Next Steps:**\n",
    "1. Re-engineer Stage 1 features and re-train with XGBoost/CatBoost.\n",
    "2. Revisit threshold tuning with cost-sensitive criteria.\n",
    "3. Hyperparameter-tune Stage 2 RF and benchmark HistGradientBoostingRegressor."
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "aa65b6d0",
   "metadata": {},
   "source": [
    "---\n",
    "# Enhanced Stage 1: User/Garage Aggregates + Recent Counts + XGBoost/CatBoost"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d8a1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import gradient boosting libraries\n",
    "# Using scikit-learn's HistGradientBoosting (no external dependencies)\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier, GradientBoostingClassifier\n",
    "print('Gradient boosting classifiers imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70962f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build enhanced features for Stage 1: aggregates only (skip recency for speed)\n",
    "# Merge aggregates into train/test (already computed earlier)\n",
    "train_enh = train_m.copy()\n",
    "test_enh = test_m.copy()\n",
    "\n",
    "# Enhanced feature set for Stage 1: base + user/garage aggregates\n",
    "enh_num = base_num + ['user_session_count','user_avg_duration','user_avg_energy',\n",
    "                       'garage_session_count','garage_avg_duration','garage_avg_energy']\n",
    "enh_cat = base_cat\n",
    "\n",
    "print(f'Enhanced features: {len(enh_num)} numerical, {len(enh_cat)} categorical')\n",
    "print('Numerical:', enh_num)\n",
    "print('Categorical:', enh_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2704c1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess enhanced features\n",
    "preprocessor_enh = ColumnTransformer([\n",
    "    ('num', StandardScaler(), enh_num),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore'), enh_cat)\n",
    "])\n",
    "\n",
    "X_train_enh = train_enh[enh_num + enh_cat]\n",
    "y_train_enh_short = train_enh['is_short_session'].astype(int)\n",
    "y_train_enh_long = (1 - y_train_enh_short).astype(int)\n",
    "\n",
    "X_test_enh = test_enh[enh_num + enh_cat]\n",
    "y_test_enh_short = test_enh['is_short_session'].astype(int)\n",
    "y_test_enh_long = (1 - y_test_enh_short).astype(int)\n",
    "\n",
    "X_train_enh_p = preprocessor_enh.fit_transform(X_train_enh)\n",
    "X_test_enh_p = preprocessor_enh.transform(X_test_enh)\n",
    "\n",
    "print(f'Enhanced train: {X_train_enh_p.shape}')\n",
    "print(f'Enhanced test: {X_test_enh_p.shape}')\n",
    "print(f'Class balance (Long): Train {y_train_enh_long.mean():.3%} | Test {y_test_enh_long.mean():.3%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd63683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train HistGradientBoosting classifier (fast, native sklearn)\n",
    "scale_pos = (1 - y_train_enh_long.mean()) / y_train_enh_long.mean()\n",
    "\n",
    "# Convert to dense if sparse\n",
    "X_train_dense = X_train_enh_p.toarray() if hasattr(X_train_enh_p, 'toarray') else X_train_enh_p\n",
    "X_test_dense = X_test_enh_p.toarray() if hasattr(X_test_enh_p, 'toarray') else X_test_enh_p\n",
    "\n",
    "hgb_clf = HistGradientBoostingClassifier(\n",
    "    max_iter=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=20,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Compute sample weights to handle imbalance\n",
    "sample_weights = np.where(y_train_enh_long == 1, scale_pos, 1.0)\n",
    "\n",
    "hgb_clf.fit(\n",
    "    X_train_dense, y_train_enh_long,\n",
    "    sample_weight=sample_weights\n",
    ")\n",
    "\n",
    "proba_long_hgb = hgb_clf.predict_proba(X_test_dense)[:, 1]\n",
    "auc_hgb = roc_auc_score(y_test_enh_long, proba_long_hgb)\n",
    "print(f'HistGradientBoosting AUC (Long): {auc_hgb:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc26ff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GradientBoosting classifier (traditional sklearn)\n",
    "gb_clf = GradientBoostingClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "gb_clf.fit(\n",
    "    X_train_dense, y_train_enh_long,\n",
    "    sample_weight=sample_weights\n",
    ")\n",
    "\n",
    "proba_long_gb = gb_clf.predict_proba(X_test_dense)[:, 1]\n",
    "auc_gb = roc_auc_score(y_test_enh_long, proba_long_gb)\n",
    "print(f'GradientBoosting AUC (Long): {auc_gb:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a4531d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare models and tune thresholds\n",
    "models = {\n",
    "    'Baseline_MLP': proba_long,\n",
    "    'HistGradientBoosting': proba_long_hgb,\n",
    "    'GradientBoosting': proba_long_gb\n",
    "}\n",
    "\n",
    "results = []\n",
    "for name, proba in models.items():\n",
    "    best_thr = {'thr':0.5,'f1':-1,'prec':0,'rec':0,'auc':0}\n",
    "    auc_score = roc_auc_score(y_test_enh_long, proba)\n",
    "    \n",
    "    for t in np.linspace(0.1, 0.9, 40):\n",
    "        y_pred = (proba >= t).astype(int)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(y_test_enh_long, y_pred, average='binary', zero_division=0)\n",
    "        if f1 > best_thr['f1']:\n",
    "            best_thr = {'thr':float(t),'f1':float(f1),'prec':float(prec),'rec':float(rec),'auc':float(auc_score)}\n",
    "    \n",
    "    results.append({'model': name, **best_thr})\n",
    "    print(f\"{name:23} | AUC: {auc_score:.3f} | Thr: {best_thr['thr']:.3f} | F1: {best_thr['f1']:.3f} | Prec: {best_thr['prec']:.3f} | Rec: {best_thr['rec']:.3f}\")\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "best_model = results_df.loc[results_df['auc'].idxmax(), 'model']\n",
    "print(f'\\nBest model by AUC: {best_model}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b465cc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, compute baseline pipeline metrics for comparison\n",
    "pred_short_mask_baseline = (proba_long >= thr).astype(bool)\n",
    "pred_long_mask_baseline = ~pred_short_mask_baseline\n",
    "\n",
    "# Baseline regression on predicted-short\n",
    "X_test_reg_baseline = test_enh.loc[pred_short_mask_baseline, num2 + cat2]\n",
    "y_test_reg_baseline = test_enh.loc[pred_short_mask_baseline, 'Duration_hours'].values\n",
    "\n",
    "if len(X_test_reg_baseline) > 0:\n",
    "    y_pred_log_baseline = rf_pipe.predict(X_test_reg_baseline)\n",
    "    y_pred_baseline = np.expm1(y_pred_log_baseline)\n",
    "    \n",
    "    rmse_pred_short_baseline = np.sqrt(mean_squared_error(y_test_reg_baseline, y_pred_baseline))\n",
    "    mae_pred_short_baseline = mean_absolute_error(y_test_reg_baseline, y_pred_baseline)\n",
    "    r2_pred_short_baseline = r2_score(y_test_reg_baseline, y_pred_baseline) if len(y_pred_baseline) > 1 else np.nan\n",
    "else:\n",
    "    rmse_pred_short_baseline = np.nan\n",
    "    mae_pred_short_baseline = np.nan\n",
    "    r2_pred_short_baseline = np.nan\n",
    "    y_pred_baseline = np.array([])\n",
    "    y_test_reg_baseline = np.array([])\n",
    "\n",
    "coverage_baseline = pred_short_mask_baseline.mean()\n",
    "\n",
    "# First, compute baseline pipeline metrics for comparison\n",
    "pred_short_mask_baseline = (proba_long >= thr).astype(bool)\n",
    "pred_long_mask_baseline = ~pred_short_mask_baseline\n",
    "\n",
    "# Baseline regression on predicted-short\n",
    "X_test_reg_baseline = test_enh.loc[pred_short_mask_baseline, num2 + cat2]\n",
    "y_test_reg_baseline = test_enh.loc[pred_short_mask_baseline, 'Duration_hours'].values\n",
    "\n",
    "if len(X_test_reg_baseline) > 0:\n",
    "    y_pred_log_baseline = rf_pipe.predict(X_test_reg_baseline)\n",
    "    y_pred_baseline = np.expm1(y_pred_log_baseline)\n",
    "    \n",
    "    rmse_pred_short_baseline = np.sqrt(mean_squared_error(y_test_reg_baseline, y_pred_baseline))\n",
    "    mae_pred_short_baseline = mean_absolute_error(y_test_reg_baseline, y_pred_baseline)\n",
    "    r2_pred_short_baseline = r2_score(y_test_reg_baseline, y_pred_baseline) if len(y_pred_baseline) > 1 else np.nan\n",
    "else:\n",
    "    rmse_pred_short_baseline = np.nan\n",
    "    mae_pred_short_baseline = np.nan\n",
    "    r2_pred_short_baseline = np.nan\n",
    "    y_pred_baseline = np.array([])\n",
    "    y_test_reg_baseline = np.array([])\n",
    "\n",
    "coverage_baseline = pred_short_mask_baseline.mean()\n",
    "\n",
    "# First, compute baseline pipeline metrics for comparison\n",
    "pred_short_mask_baseline = (proba_long >= thr).astype(bool)\n",
    "pred_long_mask_baseline = ~pred_short_mask_baseline\n",
    "\n",
    "# Baseline regression on predicted-short\n",
    "X_test_reg_baseline = test_enh.loc[pred_short_mask_baseline, num2 + cat2]\n",
    "y_test_reg_baseline = test_enh.loc[pred_short_mask_baseline, 'Duration_hours'].values\n",
    "\n",
    "if len(X_test_reg_baseline) > 0:\n",
    "    y_pred_log_baseline = rf_pipe.predict(X_test_reg_baseline)\n",
    "    y_pred_baseline = np.expm1(y_pred_log_baseline)\n",
    "    \n",
    "    rmse_pred_short_baseline = np.sqrt(mean_squared_error(y_test_reg_baseline, y_pred_baseline))\n",
    "    mae_pred_short_baseline = mean_absolute_error(y_test_reg_baseline, y_pred_baseline)\n",
    "    r2_pred_short_baseline = r2_score(y_test_reg_baseline, y_pred_baseline) if len(y_pred_baseline) > 1 else np.nan\n",
    "else:\n",
    "    rmse_pred_short_baseline = np.nan\n",
    "    mae_pred_short_baseline = np.nan\n",
    "    r2_pred_short_baseline = np.nan\n",
    "    y_pred_baseline = np.array([])\n",
    "    y_test_reg_baseline = np.array([])\n",
    "\n",
    "coverage_baseline = pred_short_mask_baseline.mean()\n",
    "\n",
    "# Re-run pipeline with best model\n",
    "# Select best model probabilities\n",
    "if best_model == 'HistGradientBoosting':\n",
    "    proba_best = proba_long_hgb\n",
    "    best_thr_val = results_df[results_df['model']=='HistGradientBoosting']['thr'].values[0]\n",
    "elif best_model == 'GradientBoosting':\n",
    "    proba_best = proba_long_gb\n",
    "    best_thr_val = results_df[results_df['model']=='GradientBoosting']['thr'].values[0]\n",
    "else:\n",
    "    proba_best = proba_long\n",
    "    best_thr_val = results_df[results_df['model']=='Baseline_MLP']['thr'].values[0]\n",
    "\n",
    "# Route with best model\n",
    "pred_long_mask_v2 = (proba_best >= best_thr_val)\n",
    "pred_short_mask_v2 = ~pred_long_mask_v2\n",
    "\n",
    "# Regression on predicted-short subset (use test_enh which has recency features)\n",
    "X_test_reg_v2 = test_enh.loc[pred_short_mask_v2, num2 + cat2]\n",
    "y_test_reg_v2 = test_enh.loc[pred_short_mask_v2, 'Duration_hours'].values\n",
    "\n",
    "if len(X_test_reg_v2) > 0:\n",
    "    y_pred_log_v2 = rf_pipe.predict(X_test_reg_v2)\n",
    "    y_pred_v2 = np.expm1(y_pred_log_v2)\n",
    "    \n",
    "    rmse_v2 = np.sqrt(mean_squared_error(y_test_reg_v2, y_pred_v2))\n",
    "    mae_v2 = mean_absolute_error(y_test_reg_v2, y_pred_v2)\n",
    "    r2_v2 = r2_score(y_test_reg_v2, y_pred_v2) if len(y_pred_v2) > 1 else np.nan\n",
    "else:\n",
    "    rmse_v2, mae_v2, r2_v2 = np.nan, np.nan, np.nan\n",
    "\n",
    "# Also compute on actual-short for comparison\n",
    "actual_short_mask_v2 = (test_enh['Duration_hours'] < 24).values\n",
    "X_test_actual_v2 = test_enh.loc[actual_short_mask_v2, num2 + cat2]\n",
    "y_test_actual_v2 = test_enh.loc[actual_short_mask_v2, 'Duration_hours'].values\n",
    "\n",
    "y_pred_log_actual_v2 = rf_pipe.predict(X_test_actual_v2)\n",
    "y_pred_actual_v2 = np.expm1(y_pred_log_actual_v2)\n",
    "\n",
    "rmse_actual_v2 = np.sqrt(mean_squared_error(y_test_actual_v2, y_pred_actual_v2))\n",
    "mae_actual_v2 = mean_absolute_error(y_test_actual_v2, y_pred_actual_v2)\n",
    "r2_actual_v2 = r2_score(y_test_actual_v2, y_pred_actual_v2)\n",
    "\n",
    "coverage_v2 = pred_short_mask_v2.mean()\n",
    "\n",
    "print(f'\\n=== Enhanced Pipeline with {best_model} ===')\n",
    "print(f'Coverage predicted-short: {coverage_v2:.3%}')\n",
    "print(f'Predicted-short metrics: RMSE {rmse_v2:.3f} | MAE {mae_v2:.3f} | R2 {r2_v2:.3f}')\n",
    "print(f'Actual-short metrics:    RMSE {rmse_actual_v2:.3f} | MAE {mae_actual_v2:.3f} | R2 {r2_actual_v2:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d649929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save enhanced pipeline metrics and visualizations\n",
    "metrics_v2 = {\n",
    "    'model': best_model,\n",
    "    'auc_long': float(results_df[results_df['model']==best_model]['auc'].values[0]),\n",
    "    'best_threshold': float(best_thr_val),\n",
    "    'precision_long': float(results_df[results_df['model']==best_model]['prec'].values[0]),\n",
    "    'recall_long': float(results_df[results_df['model']==best_model]['rec'].values[0]),\n",
    "    'f1_long': float(results_df[results_df['model']==best_model]['f1'].values[0]),\n",
    "    'coverage_predicted_short': float(coverage_v2),\n",
    "    'rmse_predicted_short': float(rmse_v2),\n",
    "    'mae_predicted_short': float(mae_v2),\n",
    "    'r2_predicted_short': float(r2_v2),\n",
    "    'rmse_actual_short': float(rmse_actual_v2),\n",
    "    'mae_actual_short': float(mae_actual_v2),\n",
    "    'r2_actual_short': float(r2_actual_v2),\n",
    "}\n",
    "\n",
    "pd.DataFrame([metrics_v2]).to_csv('fig/pipeline/pipeline_metrics_enhanced.csv', index=False)\n",
    "results_df.to_csv('fig/pipeline/classifier_comparison.csv', index=False)\n",
    "print('\u2713 Saved enhanced metrics to fig/pipeline/pipeline_metrics_enhanced.csv')\n",
    "print('\u2713 Saved classifier comparison to fig/pipeline/classifier_comparison.csv')\n",
    "\n",
    "# Confusion matrix for best model\n",
    "y_pred_long_v2 = (proba_best >= best_thr_val).astype(int)\n",
    "cm_v2 = confusion_matrix(y_test_enh_long, y_pred_long_v2)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(11, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=axes[0])\n",
    "axes[0].set_title('Baseline MLP')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "axes[0].set_ylabel('Actual')\n",
    "\n",
    "sns.heatmap(cm_v2, annot=True, fmt='d', cmap='Greens', cbar=False, ax=axes[1])\n",
    "axes[1].set_title(f'Enhanced {best_model}')\n",
    "axes[1].set_xlabel('Predicted')\n",
    "axes[1].set_ylabel('Actual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig/pipeline/confusion_comparison.png', dpi=120)\n",
    "plt.show()\n",
    "\n",
    "# Regression scatter comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "if len(y_pred_baseline) > 0 and len(y_test_reg_baseline) > 0:\n",
    "    axes[0].scatter(y_test_reg_baseline, y_pred_baseline, s=8, alpha=0.5, color='blue')\n",
    "    mn, mx = y_test_reg_baseline.min(), y_test_reg_baseline.max()\n",
    "    axes[0].plot([mn, mx], [mn, mx], 'k--', lw=1)\n",
    "axes[0].set_xlabel('Actual Duration (h)')\n",
    "axes[0].set_ylabel('Predicted Duration (h)')\n",
    "axes[0].set_title(f'Baseline MLP: RMSE={rmse_pred_short_baseline:.2f}, R\u00b2={r2_pred_short_baseline:.3f}')\n",
    "\n",
    "if len(y_pred_v2) > 0 and len(y_test_reg_v2) > 0:\n",
    "    axes[1].scatter(y_test_reg_v2, y_pred_v2, s=8, alpha=0.5, color='green')\n",
    "    mn2, mx2 = y_test_reg_v2.min(), y_test_reg_v2.max()\n",
    "    axes[1].plot([mn2, mx2], [mn2, mx2], 'k--', lw=1)\n",
    "axes[1].set_xlabel('Actual Duration (h)')\n",
    "axes[1].set_ylabel('Predicted Duration (h)')\n",
    "axes[1].set_title(f'Enhanced {best_model}: RMSE={rmse_v2:.2f}, R\u00b2={r2_v2:.3f}')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig/pipeline/regression_comparison.png', dpi=120)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbadd9c1",
   "metadata": {},
   "source": [
    "---\n",
    "# Operational Threshold Tuning with Cost-Sensitive Criteria"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d145ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost-sensitive threshold tuning: business-driven trade-offs\n",
    "# Define costs: False Negative (miss a long session) vs False Positive (wrongly flag as long)\n",
    "# Scenario: Missing a long session is more costly (customer dissatisfaction, resource misallocation)\n",
    "cost_fn = 10  # Cost of False Negative (missing a long session)\n",
    "cost_fp = 1   # Cost of False Positive (false alarm for long session)\n",
    "\n",
    "print(f'Cost Configuration: FN={cost_fn}, FP={cost_fp} (ratio {cost_fn}:{cost_fp})')\n",
    "print('Interpretation: Missing a long session is 10x more costly than a false alarm\\n')\n",
    "\n",
    "# Evaluate total cost at different thresholds\n",
    "thresholds_cost = np.linspace(0.1, 0.9, 50)\n",
    "costs = []\n",
    "\n",
    "for t in thresholds_cost:\n",
    "    y_pred_cost = (proba_best >= t).astype(int)\n",
    "    cm_cost = confusion_matrix(y_test_enh_long, y_pred_cost)\n",
    "    \n",
    "    # Confusion matrix: [[TN, FP], [FN, TP]]\n",
    "    tn, fp, fn, tp = cm_cost.ravel()\n",
    "    \n",
    "    # Total cost = (FN * cost_fn) + (FP * cost_fp)\n",
    "    total_cost = (fn * cost_fn) + (fp * cost_fp)\n",
    "    \n",
    "    # Also compute metrics for interpretation\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    \n",
    "    costs.append({\n",
    "        'threshold': t,\n",
    "        'total_cost': total_cost,\n",
    "        'fn': fn,\n",
    "        'fp': fp,\n",
    "        'tp': tp,\n",
    "        'tn': tn,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    })\n",
    "\n",
    "costs_df = pd.DataFrame(costs)\n",
    "optimal_idx = costs_df['total_cost'].idxmin()\n",
    "optimal_threshold = costs_df.loc[optimal_idx, 'threshold']\n",
    "optimal_cost = costs_df.loc[optimal_idx, 'total_cost']\n",
    "\n",
    "print(f'Optimal threshold (cost-minimization): {optimal_threshold:.3f}')\n",
    "print(f'Minimum total cost: {optimal_cost:.0f}')\n",
    "print(f\"At optimal threshold:\")\n",
    "print(f\"  - FN: {costs_df.loc[optimal_idx, 'fn']:.0f} (missed long sessions)\")\n",
    "print(f\"  - FP: {costs_df.loc[optimal_idx, 'fp']:.0f} (false alarms)\")\n",
    "print(f\"  - TP: {costs_df.loc[optimal_idx, 'tp']:.0f} (correctly caught long)\")\n",
    "print(f\"  - Recall: {costs_df.loc[optimal_idx, 'recall']:.3f}\")\n",
    "print(f\"  - Precision: {costs_df.loc[optimal_idx, 'precision']:.3f}\")\n",
    "print(f\"  - F1: {costs_df.loc[optimal_idx, 'f1']:.3f}\")\n",
    "\n",
    "# Plot cost curve\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Cost vs Threshold\n",
    "axes[0].plot(costs_df['threshold'], costs_df['total_cost'], 'b-', linewidth=2)\n",
    "axes[0].axvline(optimal_threshold, color='r', linestyle='--', label=f'Optimal: {optimal_threshold:.3f}')\n",
    "axes[0].axvline(best_thr_val, color='orange', linestyle='--', label=f'F1-based: {best_thr_val:.3f}')\n",
    "axes[0].set_xlabel('Threshold')\n",
    "axes[0].set_ylabel('Total Cost')\n",
    "axes[0].set_title(f'Cost-Sensitive Threshold (FN={cost_fn}, FP={cost_fp})')\n",
    "axes[0].legend()\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "# FN and FP breakdown\n",
    "axes[1].plot(costs_df['threshold'], costs_df['fn'], 'r-', linewidth=2, label='False Negatives (FN)')\n",
    "axes[1].plot(costs_df['threshold'], costs_df['fp'], 'orange', linewidth=2, label='False Positives (FP)')\n",
    "axes[1].axvline(optimal_threshold, color='r', linestyle='--', alpha=0.5)\n",
    "axes[1].set_xlabel('Threshold')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title('FN vs FP Trade-off')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig/pipeline/cost_sensitive_threshold.png', dpi=120)\n",
    "plt.show()\n",
    "\n",
    "print(f'\\nComparison: F1-based threshold {best_thr_val:.3f} vs Cost-based {optimal_threshold:.3f}')\n",
    "print(f'Cost reduction: {costs_df[costs_df[\"threshold\"]==best_thr_val][\"total_cost\"].values[0]:.0f} \u2192 {optimal_cost:.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17866e21",
   "metadata": {},
   "source": [
    "---\n",
    "# Stage 2 Hyperparameter Tuning & HistGradientBoosting Benchmark"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881e26ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF Hyperparameter Grid Search (on short-only training data)\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Use short-only training data (same as Stage 2)\n",
    "train_short_s2 = train_m[train_m['Duration_hours'] < 24].copy()\n",
    "X_train_s2 = train_short_s2[num2 + cat2].copy()\n",
    "y_train_s2 = np.log1p(train_short_s2['Duration_hours'].values)\n",
    "\n",
    "# Test set: actual short sessions\n",
    "test_short_s2 = test_m[test_m['Duration_hours'] < 24].copy()\n",
    "X_test_s2 = test_short_s2[num2 + cat2].copy()\n",
    "y_test_s2 = np.log1p(test_short_s2['Duration_hours'].values)\n",
    "y_test_s2_orig = test_short_s2['Duration_hours'].values\n",
    "\n",
    "# Define RF parameter grid (focused on key parameters to keep runtime reasonable)\n",
    "param_grid_rf = {\n",
    "    'rf__n_estimators': [200, 300, 400],\n",
    "    'rf__max_depth': [8, 12, 16],\n",
    "    'rf__min_samples_leaf': [1, 2, 4],\n",
    "    'rf__min_samples_split': [2, 5]\n",
    "}\n",
    "\n",
    "print(f'Grid search space: {len(param_grid_rf[\"rf__n_estimators\"]) * len(param_grid_rf[\"rf__max_depth\"]) * len(param_grid_rf[\"rf__min_samples_leaf\"]) * len(param_grid_rf[\"rf__min_samples_split\"])} combinations')\n",
    "print('Starting RF grid search (this may take 2-3 minutes)...\\n')\n",
    "\n",
    "# Create base RF pipeline\n",
    "rf_base = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
    "rf_pipe_base = Pipeline([('prep', preprocessor_reg), ('rf', rf_base)])\n",
    "\n",
    "# Grid search with 3-fold CV\n",
    "grid_search_rf = GridSearchCV(\n",
    "    rf_pipe_base,\n",
    "    param_grid_rf,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search_rf.fit(X_train_s2, y_train_s2)\n",
    "\n",
    "print('\\n=== RF Grid Search Results ===')\n",
    "print(f'Best parameters: {grid_search_rf.best_params_}')\n",
    "print(f'Best CV score (neg MSE): {grid_search_rf.best_score_:.3f}')\n",
    "\n",
    "# Evaluate best RF on test set\n",
    "y_pred_log_rf_best = grid_search_rf.predict(X_test_s2)\n",
    "y_pred_rf_best = np.expm1(y_pred_log_rf_best)\n",
    "\n",
    "rmse_rf_best = np.sqrt(mean_squared_error(y_test_s2_orig, y_pred_rf_best))\n",
    "mae_rf_best = mean_absolute_error(y_test_s2_orig, y_pred_rf_best)\n",
    "r2_rf_best = r2_score(y_test_s2_orig, y_pred_rf_best)\n",
    "\n",
    "print(f'\\nBest RF Test Performance:')\n",
    "print(f'  RMSE: {rmse_rf_best:.3f}')\n",
    "print(f'  MAE:  {mae_rf_best:.3f}')\n",
    "print(f'  R\u00b2:   {r2_rf_best:.3f}')\n",
    "print(f'\\nImprovement over baseline RF (RMSE {rmse_actual_short:.3f}):')\n",
    "print(f'  RMSE: {rmse_actual_short - rmse_rf_best:+.3f} ({(rmse_actual_short - rmse_rf_best)/rmse_actual_short*100:+.1f}%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adff6ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "\n",
    "print('Training HistGradientBoostingRegressor...')\n",
    "\n",
    "# Train with log1p target (preprocessor already fitted)\n",
    "X_train_s2_p = preprocessor_reg.transform(X_train_s2)\n",
    "X_test_s2_p = preprocessor_reg.transform(X_test_s2)\n",
    "\n",
    "# Convert to dense if needed\n",
    "X_train_s2_dense = X_train_s2_p.toarray() if hasattr(X_train_s2_p, 'toarray') else X_train_s2_p\n",
    "X_test_s2_dense = X_test_s2_p.toarray() if hasattr(X_test_s2_p, 'toarray') else X_test_s2_p\n",
    "\n",
    "hgb_reg = HistGradientBoostingRegressor(\n",
    "    max_iter=300,\n",
    "    max_depth=8,\n",
    "    learning_rate=0.05,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=20,\n",
    "    random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "hgb_reg.fit(X_train_s2_dense, y_train_s2)\n",
    "\n",
    "y_pred_log_hgb = hgb_reg.predict(X_test_s2_dense)\n",
    "y_pred_hgb = np.expm1(y_pred_log_hgb)\n",
    "\n",
    "rmse_hgb = np.sqrt(mean_squared_error(y_test_s2_orig, y_pred_hgb))\n",
    "mae_hgb = mean_absolute_error(y_test_s2_orig, y_pred_hgb)\n",
    "r2_hgb = r2_score(y_test_s2_orig, y_pred_hgb)\n",
    "\n",
    "print(f'\\nHistGradientBoosting Test Performance:')\n",
    "print(f'  RMSE: {rmse_hgb:.3f}')\n",
    "print(f'  MAE:  {mae_hgb:.3f}')\n",
    "print(f'  R\u00b2:   {r2_hgb:.3f}')\n",
    "print(f'\\nImprovement over baseline RF (RMSE {rmse_actual_short:.3f}):')\n",
    "print(f'  RMSE: {rmse_actual_short - rmse_hgb:+.3f} ({(rmse_actual_short - rmse_hgb)/rmse_actual_short*100:+.1f}%)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}