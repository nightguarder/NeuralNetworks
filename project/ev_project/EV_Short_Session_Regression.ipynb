{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8f2d177",
   "metadata": {},
   "source": [
    "# EV Charging: Short-Session Duration Prediction (<24h)\n",
    "\n",
    "**Goal:** Predict charging duration for short sessions using Neural Network with advanced behavioral features.\n",
    "\n",
    "**Approach:** Train MLP with user charging patterns, temporal interactions, and robust loss function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae3f12b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90ebd13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total sessions: 6745 | Short-only: 6289\n",
      "Columns: ['session_ID', 'Garage_ID', 'User_ID', 'User_type', 'Shared_ID', 'Start_plugin', 'Start_plugin_hour', 'End_plugout', 'End_plugout_hour', 'El_kWh', 'Duration_hours', 'month_plugin', 'weekdays_plugin', 'Plugin_category', 'Duration_category', 'Start_plugin_dt', 'date', 'temp', 'precip', 'clouds', 'solar_rad', 'wind_spd', 'End_plugout_dt', 'Duration_check', 'temp_filled', 'precip_filled', 'clouds_filled', 'solar_rad_filled', 'hour', 'hour_sin', 'hour_cos', 'weekday', 'is_rainy', 'is_overcast', 'is_sunny', 'is_short_session']\n"
     ]
    }
   ],
   "source": [
    "# Load and filter to short sessions (<24h)\n",
    "df = pd.read_csv('data/ev_sessions_clean.csv')\n",
    "df_short = df[df['is_short_session'] == 1].copy()\n",
    "print(f'Total sessions: {len(df)} | Short-only: {len(df_short)}')\n",
    "print('Columns:', df_short.columns.tolist())\n",
    "\n",
    "target_col = 'Duration_hours'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ede4b3",
   "metadata": {},
   "source": [
    "## Feature Engineering: User/Garage Aggregates\n",
    "\n",
    "Create behavioral features to capture user charging patterns and garage characteristics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2478b4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base + Aggregate Features:\n",
      "  Numerical: 13 features\n",
      "  Categorical: 3 features\n",
      "  X2 shape: (6289, 16)\n"
     ]
    }
   ],
   "source": [
    "# Build user and garage aggregates\n",
    "user_agg = df_short.groupby('User_ID').agg(\n",
    "    user_session_count=('session_ID','count'),\n",
    "    user_avg_duration=('Duration_hours','mean'),\n",
    "    user_avg_energy=('El_kWh','mean')\n",
    ").reset_index()\n",
    "\n",
    "garage_agg = df_short.groupby('Garage_ID').agg(\n",
    "    garage_session_count=('session_ID','count'),\n",
    "    garage_avg_duration=('Duration_hours','mean'),\n",
    "    garage_avg_energy=('El_kWh','mean')\n",
    ").reset_index()\n",
    "\n",
    "df_feat = (\n",
    "    df_short.merge(user_agg, on='User_ID', how='left')\n",
    "            .merge(garage_agg, on='Garage_ID', how='left')\n",
    ")\n",
    "\n",
    "agg_num_cols = ['user_session_count','user_avg_duration','user_avg_energy',\n",
    "                'garage_session_count','garage_avg_duration','garage_avg_energy']\n",
    "num_base = ['hour_sin','hour_cos','temp','precip','wind_spd','clouds','solar_rad']\n",
    "cat_base = ['weekday','Garage_ID','month_plugin']\n",
    "\n",
    "numerical_cols2 = [c for c in num_base + agg_num_cols if c in df_feat.columns]\n",
    "categorical_cols2 = [c for c in cat_base if c in df_feat.columns]\n",
    "\n",
    "X2 = df_feat[numerical_cols2 + categorical_cols2].copy()\n",
    "y2 = df_feat[target_col].copy()\n",
    "\n",
    "print('Base + Aggregate Features:')\n",
    "print(f'  Numerical: {len(numerical_cols2)} features')\n",
    "print(f'  Categorical: {len(categorical_cols2)} features')\n",
    "print(f'  X2 shape: {X2.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5c340d76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed shapes: (5031, 56), (1258, 56)\n"
     ]
    }
   ],
   "source": [
    "# Preprocess aggregate features\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "preprocessor2 = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numerical_cols2),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols2)\n",
    "])\n",
    "\n",
    "X_train2_p = preprocessor2.fit_transform(X_train2)\n",
    "X_test2_p = preprocessor2.transform(X_test2)\n",
    "print(f'Processed shapes: {X_train2_p.shape}, {X_test2_p.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad896b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cyrils/Developer/Python/NeuralNetworks/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline MLP: RMSE=5.915, MAE=4.280, R²=0.169\n"
     ]
    }
   ],
   "source": [
    "# Train baseline MLP with aggregate features (for comparison)\n",
    "def build_mlp_baseline(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_shape=(input_dim,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "mlp2 = build_mlp_baseline(X_train2_p.shape[1])\n",
    "es2 = EarlyStopping(patience=10, restore_best_weights=True, monitor='val_loss', mode='min', verbose=0)\n",
    "\n",
    "y_train2_log = np.log1p(y_train2)\n",
    "history2 = mlp2.fit(X_train2_p, y_train2_log, validation_data=(X_test2_p, np.log1p(y_test2)), \n",
    "                    epochs=100, batch_size=32, callbacks=[es2], verbose=0)\n",
    "\n",
    "y_pred_mlp2 = np.expm1(mlp2.predict(X_test2_p, verbose=0).ravel())\n",
    "rmse_mlp2 = np.sqrt(mean_squared_error(y_test2, y_pred_mlp2))\n",
    "mae_mlp2 = mean_absolute_error(y_test2, y_pred_mlp2)\n",
    "r2_mlp2 = r2_score(y_test2, y_pred_mlp2)\n",
    "print(f'Baseline MLP: RMSE={rmse_mlp2:.3f}, MAE={mae_mlp2:.3f}, R²={r2_mlp2:.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2149048f",
   "metadata": {},
   "source": [
    "## Advanced Behavioral Features\n",
    "\n",
    "Engineer user charging patterns, temporal interactions, and energy efficiency metrics to give the neural network better context about individual behavior.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f854478d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error analysis helper function\n",
    "def analyze_errors_by_range(y_true, y_pred, model_name):\n",
    "    \"\"\"Analyze MAE across different duration ranges\"\"\"\n",
    "    errors = np.abs(y_true - y_pred)\n",
    "    \n",
    "    ranges = [\n",
    "        (0, 2, 'Ultra-short (0-2h)'),\n",
    "        (2, 5, 'Short (2-5h)'),\n",
    "        (5, 10, 'Medium (5-10h)'),\n",
    "        (10, 24, 'Long-short (10-24h)')\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n{model_name} - Error Analysis by Duration Range:\")\n",
    "    print(\"=\"*70)\n",
    "    for low, high, label in ranges:\n",
    "        mask = (y_true >= low) & (y_true < high)\n",
    "        if mask.sum() > 0:\n",
    "            range_mae = errors[mask].mean()\n",
    "            range_count = mask.sum()\n",
    "            pct = (range_count / len(y_true)) * 100\n",
    "            print(f\"{label:<25} | Count: {range_count:4d} ({pct:5.1f}%) | MAE: {range_mae:.2f}h\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f266797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize improvement\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].scatter(y_test2, y_pred_mlp2, s=15, alpha=0.4, color='red')\n",
    "axes[0].plot([y_test2.min(), y_test2.max()], [y_test2.min(), y_test2.max()], 'k--', lw=2)\n",
    "axes[0].set_xlabel('Actual Duration (hours)', fontsize=11)\n",
    "axes[0].set_ylabel('Predicted Duration (hours)', fontsize=11)\n",
    "axes[0].set_title(f'Baseline MLP\\nMAE = {mae_mlp2:.2f}h, R² = {r2_mlp2:.3f}', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].scatter(y_test3, y_pred_mlp_v4, s=15, alpha=0.4, color='green')\n",
    "axes[1].plot([y_test3.min(), y_test3.max()], [y_test3.min(), y_test3.max()], 'k--', lw=2)\n",
    "axes[1].set_xlabel('Actual Duration (hours)', fontsize=11)\n",
    "axes[1].set_ylabel('Predicted Duration (hours)', fontsize=11)\n",
    "axes[1].set_title(f'MLP V4 (Advanced)\\nMAE = {mae_mlp_v4:.2f}h, R² = {r2_mlp_v4:.3f}', fontsize=12, fontweight='bold')\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('fig/modeling_regularized/mlp_v4_improvement.png', dpi=120, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f'\\n✓ Saved visualization to fig/modeling_regularized/mlp_v4_improvement.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e086ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final model comparison\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SHORT-SESSION REGRESSION: Final Model Comparison\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\n{'Model':<45} {'RMSE':<12} {'MAE':<12} {'R²':<10}\")\n",
    "print(\"-\"*80)\n",
    "print(f\"{'Baseline MLP (aggregate features)':<45} {rmse_mlp2:.3f}{'':>7} {mae_mlp2:.3f}{'':>7} {r2_mlp2:.3f}\")\n",
    "print(f\"{'MLP V4 (behavioral features + Huber) ★':<45} {rmse_mlp_v4:.3f}{'':>7} {mae_mlp_v4:.3f}{'':>7} {r2_mlp_v4:.3f}\")\n",
    "print(f\"{'Random Forest V4 (same features)':<45} {rmse_rf_v4:.3f}{'':>7} {mae_rf_v4:.3f}{'':>7} {r2_rf_v4:.3f}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "improvement_pct = ((mae_mlp2 - mae_mlp_v4) / mae_mlp2) * 100\n",
    "\n",
    "print(f\"\\n★ BEST MODEL: MLP V4 - Neural Network with Advanced Features\")\n",
    "print(f\"  → MAE improvement: {mae_mlp2:.3f}h → {mae_mlp_v4:.3f}h ({improvement_pct:.1f}% reduction)\")\n",
    "print(f\"  → Architecture: 512→256→128→64→32 neurons\")\n",
    "print(f\"  → Regularization: BatchNorm + Dropout (0.4/0.3/0.2/0.2)\")\n",
    "print(f\"  → Loss: Huber (robust to outliers)\")\n",
    "print(f\"  → Features: 24 numerical + 3 categorical\")\n",
    "\n",
    "analyze_errors_by_range(y_test3, y_pred_mlp_v4, \"\\nMLP V4 Performance\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9a2fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Random Forest V4 for comparison\n",
    "rf_v4 = RandomForestRegressor(\n",
    "    n_estimators=500,\n",
    "    max_depth=20,\n",
    "    min_samples_split=5,\n",
    "    min_samples_leaf=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_pipe_v4 = Pipeline([\n",
    "    ('prep', preprocessor3),\n",
    "    ('rf', rf_v4)\n",
    "])\n",
    "\n",
    "rf_pipe_v4.fit(X_train3, np.log1p(y_train3))\n",
    "y_pred_rf_v4 = np.expm1(rf_pipe_v4.predict(X_test3))\n",
    "\n",
    "rmse_rf_v4 = np.sqrt(mean_squared_error(y_test3, y_pred_rf_v4))\n",
    "mae_rf_v4 = mean_absolute_error(y_test3, y_pred_rf_v4)\n",
    "r2_rf_v4 = r2_score(y_test3, y_pred_rf_v4)\n",
    "\n",
    "print(f'\\n✓ Random Forest V4 (Advanced Features):')\n",
    "print(f'  RMSE: {rmse_rf_v4:.3f} | MAE: {mae_rf_v4:.3f} | R²: {r2_rf_v4:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4ce2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess advanced features and train MLP V4\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.2, random_state=42)\n",
    "\n",
    "preprocessor3 = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), numerical_cols3),\n",
    "    ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols3)\n",
    "])\n",
    "\n",
    "X_train3_p = preprocessor3.fit_transform(X_train3)\n",
    "X_test3_p = preprocessor3.transform(X_test3)\n",
    "print(f'Advanced processed shapes: {X_train3_p.shape}, {X_test3_p.shape}')\n",
    "\n",
    "def build_mlp_v4(input_dim):\n",
    "    \"\"\"Deep MLP with Huber loss for robust predictions\"\"\"\n",
    "    model = Sequential([\n",
    "        Dense(512, activation='relu', input_shape=(input_dim,)),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.4),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.2),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dropout(0.2),\n",
    "        Dense(32, activation='relu'),\n",
    "        Dense(1, activation='linear')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001), loss='huber', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "mlp_v4 = build_mlp_v4(X_train3_p.shape[1])\n",
    "es_v4 = EarlyStopping(patience=20, restore_best_weights=True, monitor='val_loss', mode='min', verbose=0)\n",
    "rlrp_v4 = ReduceLROnPlateau(patience=10, factor=0.5, monitor='val_loss', mode='min', verbose=0)\n",
    "\n",
    "history_v4 = mlp_v4.fit(\n",
    "    X_train3_p, np.log1p(y_train3),\n",
    "    validation_data=(X_test3_p, np.log1p(y_test3)),\n",
    "    epochs=200,\n",
    "    batch_size=32,\n",
    "    callbacks=[es_v4, rlrp_v4],\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "y_pred_mlp_v4 = np.expm1(mlp_v4.predict(X_test3_p, verbose=0).ravel())\n",
    "rmse_mlp_v4 = np.sqrt(mean_squared_error(y_test3, y_pred_mlp_v4))\n",
    "mae_mlp_v4 = mean_absolute_error(y_test3, y_pred_mlp_v4)\n",
    "r2_mlp_v4 = r2_score(y_test3, y_pred_mlp_v4)\n",
    "\n",
    "print(f'\\n✓ MLP V4 (Advanced Features + Huber Loss):')\n",
    "print(f'  RMSE: {rmse_mlp_v4:.3f} | MAE: {mae_mlp_v4:.3f} | R²: {r2_mlp_v4:.3f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4cb16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Engineer advanced behavioral features\n",
    "def engineer_advanced_features(df_input):\n",
    "    \"\"\"Add user behavioral patterns and temporal interactions\"\"\"\n",
    "    df = df_input.copy()\n",
    "    \n",
    "    # User charging patterns\n",
    "    user_time_patterns = df.groupby('User_ID').agg(\n",
    "        user_preferred_hour=('hour', lambda x: x.mode()[0] if len(x.mode()) > 0 else x.mean()),\n",
    "        user_weekend_pct=('weekday', lambda x: (x >= 5).sum() / len(x)),\n",
    "        user_night_pct=('hour', lambda x: ((x >= 22) | (x <= 6)).sum() / len(x))\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Energy consumption patterns\n",
    "    df['energy_per_hour'] = df['El_kWh'] / (df['Duration_hours'] + 0.01)\n",
    "    user_energy = df.groupby('User_ID').agg(\n",
    "        user_avg_power_rate=('energy_per_hour', 'mean'),\n",
    "        user_energy_std=('El_kWh', 'std')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Garage characteristics\n",
    "    garage_patterns = df.groupby('Garage_ID').agg(\n",
    "        garage_peak_hour=('hour', lambda x: x.mode()[0] if len(x.mode()) > 0 else x.mean()),\n",
    "        garage_capacity_proxy=('session_ID', 'count')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Time-based interactions\n",
    "    df['is_weekend'] = (df['weekday'] >= 5).astype(int)\n",
    "    df['is_night'] = ((df['hour'] >= 22) | (df['hour'] <= 6)).astype(int)\n",
    "    df['is_morning_rush'] = ((df['hour'] >= 7) & (df['hour'] <= 9)).astype(int)\n",
    "    \n",
    "    # Merge all features\n",
    "    df = (df.merge(user_time_patterns, on='User_ID', how='left')\n",
    "            .merge(user_energy, on='User_ID', how='left')\n",
    "            .merge(garage_patterns, on='Garage_ID', how='left'))\n",
    "    \n",
    "    # Fill missing values\n",
    "    df['user_preferred_hour'] = df['user_preferred_hour'].fillna(12)\n",
    "    df['user_weekend_pct'] = df['user_weekend_pct'].fillna(0.2)\n",
    "    df['user_night_pct'] = df['user_night_pct'].fillna(0.1)\n",
    "    df['user_avg_power_rate'] = df['user_avg_power_rate'].fillna(df['energy_per_hour'].mean())\n",
    "    df['user_energy_std'] = df['user_energy_std'].fillna(df['El_kWh'].std())\n",
    "    df['garage_peak_hour'] = df['garage_peak_hour'].fillna(12)\n",
    "    df['garage_capacity_proxy'] = df['garage_capacity_proxy'].fillna(df['garage_capacity_proxy'].median())\n",
    "    \n",
    "    return df\n",
    "\n",
    "df_feat_advanced = engineer_advanced_features(df_feat)\n",
    "\n",
    "advanced_features = [\n",
    "    'user_preferred_hour', 'user_weekend_pct', 'user_night_pct',\n",
    "    'user_avg_power_rate', 'user_energy_std',\n",
    "    'garage_peak_hour', 'garage_capacity_proxy',\n",
    "    'is_weekend', 'is_night', 'is_morning_rush',\n",
    "    'energy_per_hour'\n",
    "]\n",
    "\n",
    "numerical_cols3 = numerical_cols2 + advanced_features\n",
    "categorical_cols3 = categorical_cols2\n",
    "\n",
    "X3 = df_feat_advanced[numerical_cols3 + categorical_cols3].copy()\n",
    "y3 = df_feat_advanced[target_col].copy()\n",
    "\n",
    "print(f'Advanced Features: {len(numerical_cols3)} numerical, {len(categorical_cols3)} categorical')\n",
    "print(f'X3 shape: {X3.shape}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
