{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a79f530",
   "metadata": {},
   "source": [
    "# EV Charging Prediction with Neural Networks\n",
    "\n",
    "**Date:** January 14, 2026  \n",
    "**Purpose:** Experimental Neural Network approach for EV charging prediction\n",
    "\n",
    "---\n",
    "\n",
    "## Objective\n",
    "\n",
    "In this notebook, we explore **Multi-Layer Perceptron (MLP)** neural networks for EV charging prediction tasks. Based on our comprehensive data analysis and successful implementation of gradient boosting models, we know that:\n",
    "\n",
    "1. **Tree-based models (Random Forest, HistGradientBoosting)** achieve superior performance on this tabular dataset\n",
    "2. **Two-stage pipeline** (Classification → Regression) is the optimal approach\n",
    "3. **Pure regression on full dataset fails** due to extreme outliers and \"regression to the mean\"\n",
    "\n",
    "However, we want to demonstrate that we have explored neural network approaches as part of this course, documenting:\n",
    "- Why MLPs are less suited for small tabular datasets compared to tree ensembles\n",
    "- How regularization techniques (Dropout, L2, Early Stopping) help prevent overfitting\n",
    "- What performance we can achieve with careful hyperparameter tuning\n",
    "\n",
    "---\n",
    "\n",
    "## Approach\n",
    "\n",
    "We will implement two neural networks:\n",
    "\n",
    "### 1. **Classification MLP**: Predicting Short (<24h) vs Long (≥24h) Sessions\n",
    "   - **Architecture:** Dense layers with ReLU activation + Dropout\n",
    "   - **Output:** Sigmoid activation (binary probability)\n",
    "   - **Loss:** Binary Crossentropy with class weights\n",
    "   - **Metrics:** AUC-ROC, Precision, Recall, F1\n",
    "   - **Comparison:** vs HistGradientBoosting (AUC 0.847)\n",
    "\n",
    "### 2. **Regression MLP**: Predicting Duration for Short Sessions Only\n",
    "   - **Architecture:** Dense layers with ReLU activation + Dropout\n",
    "   - **Output:** Linear activation (continuous value)\n",
    "   - **Loss:** Mean Squared Error (MSE)\n",
    "   - **Metrics:** RMSE, MAE, R²\n",
    "   - **Comparison:** vs Random Forest (R² 0.161, RMSE 5.95h)\n",
    "\n",
    "---\n",
    "\n",
    "## Expected Outcome\n",
    "\n",
    "We expect the neural networks to **underperform** compared to tree-based models because:\n",
    "- **Dataset size:** Only ~6,000 sessions (NNs typically need 10,000+ samples)\n",
    "- **Feature type:** Tabular data with categorical variables (trees handle better)\n",
    "- **Feature interactions:** Tree models automatically capture non-linear interactions\n",
    "- **Interpretability:** Tree models provide feature importance naturally\n",
    "\n",
    "This demonstrates our understanding of when to use deep learning vs classical ML.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178202eb",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38eba486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.16.2\n",
      "Keras version: 3.13.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, precision_recall_curve,\n",
    "    confusion_matrix, classification_report,\n",
    "    mean_squared_error, mean_absolute_error, r2_score,\n",
    "    precision_recall_fscore_support\n",
    ")\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras import regularizers\n",
    "\n",
    "# For reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b5b7a2",
   "metadata": {},
   "source": [
    "## 2. Custom PlotLosses Callback\n",
    "\n",
    "This utility helps visualize training progress in real-time (adapted from Lecture 4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f463a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "class PlotLosses(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.i = 0\n",
    "        self.x = []\n",
    "        self.losses = []\n",
    "        self.val_losses = []\n",
    "        self.fig = plt.figure()\n",
    "        self.logs = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.logs.append(logs)\n",
    "        self.x.append(self.i)\n",
    "        self.losses.append(logs.get('loss'))\n",
    "        self.val_losses.append(logs.get('val_loss'))\n",
    "        self.i += 1\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        plt.plot(self.x, self.losses, label=\"Training Loss\")\n",
    "        plt.plot(self.x, self.val_losses, label=\"Validation Loss\")\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Training Progress')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "        \n",
    "plot_losses = PlotLosses()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a084fd9c",
   "metadata": {},
   "source": [
    "## 3. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0bdb26d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (6745, 36)\n",
      "\n",
      "Target distribution:\n",
      "is_short_session\n",
      "1    0.932394\n",
      "0    0.067606\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Short (<24h): 6289 sessions\n",
      "Long (≥24h): 456 sessions\n"
     ]
    }
   ],
   "source": [
    "# Load cleaned data\n",
    "df = pd.read_csv('data/ev_sessions_clean.csv')\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['is_short_session'].value_counts(normalize=True))\n",
    "print(f\"\\nShort (<24h): {df['is_short_session'].sum()} sessions\")\n",
    "print(f\"Long (≥24h): {(~df['is_short_session'].astype(bool)).sum()} sessions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c3b5294",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Duration statistics (hours):\n",
      "count    6745.000000\n",
      "mean       11.634151\n",
      "std        13.868004\n",
      "min         0.066667\n",
      "25%         2.916667\n",
      "50%        10.200000\n",
      "75%        15.283333\n",
      "max       239.233333\n",
      "Name: Duration_hours, dtype: float64\n",
      "\n",
      "Energy statistics (kWh):\n",
      "count    6745.000000\n",
      "mean       12.912255\n",
      "std        11.780111\n",
      "min         0.010000\n",
      "25%         5.380000\n",
      "50%         9.200000\n",
      "75%        16.240000\n",
      "max        80.860000\n",
      "Name: El_kWh, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Display basic statistics\n",
    "print(\"\\nDuration statistics (hours):\")\n",
    "print(df['Duration_hours'].describe())\n",
    "\n",
    "print(\"\\nEnergy statistics (kWh):\")\n",
    "print(df['El_kWh'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142015a1",
   "metadata": {},
   "source": [
    "## 4. Feature Engineering\n",
    "\n",
    "We'll create the same features used in our successful gradient boosting models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e465f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Aggregate features created:\n",
      "User-level: ['user_avg_duration', 'user_std_duration', 'user_session_count', 'user_avg_energy', 'user_std_energy']\n",
      "Garage-level: ['garage_avg_duration', 'garage_session_count', 'garage_avg_energy']\n"
     ]
    }
   ],
   "source": [
    "# Convert datetime columns\n",
    "df['Start_plugin_dt'] = pd.to_datetime(df['Start_plugin_dt'])\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "\n",
    "# Create temporal features (already exist in clean data: hour_sin, hour_cos, weekday)\n",
    "# Add month as numeric\n",
    "df['month_num'] = df['Start_plugin_dt'].dt.month\n",
    "\n",
    "# Create aggregated features per user and garage\n",
    "user_agg = df.groupby('User_ID').agg({\n",
    "    'Duration_hours': ['mean', 'std', 'count'],\n",
    "    'El_kWh': ['mean', 'std']\n",
    "}).reset_index()\n",
    "user_agg.columns = ['User_ID', 'user_avg_duration', 'user_std_duration', 'user_session_count', 'user_avg_energy', 'user_std_energy']\n",
    "user_agg['user_std_duration'] = user_agg['user_std_duration'].fillna(0)\n",
    "user_agg['user_std_energy'] = user_agg['user_std_energy'].fillna(0)\n",
    "\n",
    "garage_agg = df.groupby('Garage_ID').agg({\n",
    "    'Duration_hours': ['mean', 'count'],\n",
    "    'El_kWh': 'mean'\n",
    "}).reset_index()\n",
    "garage_agg.columns = ['Garage_ID', 'garage_avg_duration', 'garage_session_count', 'garage_avg_energy']\n",
    "\n",
    "# Merge aggregates\n",
    "df = df.merge(user_agg, on='User_ID', how='left')\n",
    "df = df.merge(garage_agg, on='Garage_ID', how='left')\n",
    "\n",
    "print(\"\\nAggregate features created:\")\n",
    "print(f\"User-level: {user_agg.columns.tolist()[1:]}\")\n",
    "print(f\"Garage-level: {garage_agg.columns.tolist()[1:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcd42b43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total features for NN: 20\n",
      "Features: ['hour_sin', 'hour_cos', 'weekday', 'month_num', 'temp_filled', 'precip_filled', 'clouds_filled', 'solar_rad_filled', 'wind_spd', 'is_rainy', 'is_overcast', 'is_sunny', 'user_avg_duration', 'user_std_duration', 'user_session_count', 'user_avg_energy', 'user_std_energy', 'garage_avg_duration', 'garage_session_count', 'garage_avg_energy']\n"
     ]
    }
   ],
   "source": [
    "# Select features for neural network\n",
    "feature_cols = [\n",
    "    # Temporal features\n",
    "    'hour_sin', 'hour_cos', 'weekday', 'month_num',\n",
    "    # Weather features\n",
    "    'temp_filled', 'precip_filled', 'clouds_filled', 'solar_rad_filled', 'wind_spd',\n",
    "    # Binary weather indicators\n",
    "    'is_rainy', 'is_overcast', 'is_sunny',\n",
    "    # User aggregates\n",
    "    'user_avg_duration', 'user_std_duration', 'user_session_count', 'user_avg_energy', 'user_std_energy',\n",
    "    # Garage aggregates\n",
    "    'garage_avg_duration', 'garage_session_count', 'garage_avg_energy'\n",
    "]\n",
    "\n",
    "print(f\"\\nTotal features for NN: {len(feature_cols)}\")\n",
    "print(f\"Features: {feature_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc9d26f9",
   "metadata": {},
   "source": [
    "## 5. Chronological Train-Test Split\n",
    "\n",
    "Following best practices, we use chronological split to simulate real-world deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "522b74e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: 5396 sessions (2018-12-21 10:24:00 to 2019-12-28 16:00:00)\n",
      "Test set: 1349 sessions (2019-12-28 16:09:00 to 2020-01-31 20:42:00)\n",
      "\n",
      "Train set - Short: 5049, Long: 347\n",
      "Test set - Short: 1240, Long: 109\n"
     ]
    }
   ],
   "source": [
    "# Sort by date\n",
    "df_sorted = df.sort_values('Start_plugin_dt').reset_index(drop=True)\n",
    "\n",
    "# 80-20 chronological split\n",
    "split_idx = int(len(df_sorted) * 0.8)\n",
    "train_df = df_sorted.iloc[:split_idx].copy()\n",
    "test_df = df_sorted.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\"Training set: {len(train_df)} sessions ({train_df['Start_plugin_dt'].min()} to {train_df['Start_plugin_dt'].max()})\")\n",
    "print(f\"Test set: {len(test_df)} sessions ({test_df['Start_plugin_dt'].min()} to {test_df['Start_plugin_dt'].max()})\")\n",
    "\n",
    "print(f\"\\nTrain set - Short: {train_df['is_short_session'].sum()}, Long: {(~train_df['is_short_session'].astype(bool)).sum()}\")\n",
    "print(f\"Test set - Short: {test_df['is_short_session'].sum()}, Long: {(~test_df['is_short_session'].astype(bool)).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6976406",
   "metadata": {},
   "source": [
    "## 6. Data Preprocessing\n",
    "\n",
    "Neural networks require standardized inputs for optimal performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "812ef1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature matrix shape: (5396, 20)\n",
      "Classification target distribution (train): [5049  347]\n",
      "  Class 0 (Short <24h): 5049 (93.6%)\n",
      "  Class 1 (Long ≥24h): 347 (6.4%)\n"
     ]
    }
   ],
   "source": [
    "# Prepare feature matrices\n",
    "X_train = train_df[feature_cols].values\n",
    "X_test = test_df[feature_cols].values\n",
    "\n",
    "# Classification targets\n",
    "y_train_cls = (~train_df['is_short_session'].astype(bool)).astype(int).values  # 1 = Long (≥24h), 0 = Short\n",
    "y_test_cls = (~test_df['is_short_session'].astype(bool)).astype(int).values\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\nFeature matrix shape: {X_train_scaled.shape}\")\n",
    "print(f\"Classification target distribution (train): {np.bincount(y_train_cls)}\")\n",
    "print(f\"  Class 0 (Short <24h): {(y_train_cls == 0).sum()} ({(y_train_cls == 0).mean():.1%})\")\n",
    "print(f\"  Class 1 (Long ≥24h): {(y_train_cls == 1).sum()} ({(y_train_cls == 1).mean():.1%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27fc09d",
   "metadata": {},
   "source": [
    "## 7. TASK 1: Classification Neural Network\n",
    "\n",
    "### Objective: Predict whether a session will be Long (≥24h) or Short (<24h)\n",
    "\n",
    "**Baseline to beat:** HistGradientBoosting with AUC = 0.847"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00e2a567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights: {0: 0.5343632402455932, 1: 7.77521613832853}\n",
      "  Short (<24h): 0.534\n",
      "  Long (≥24h): 7.775\n",
      "\n",
      "✓ Unified model builders and training utilities loaded\n"
     ]
    }
   ],
   "source": [
    "# Calculate class weights for imbalanced data\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.array([0, 1]), y=y_train_cls)\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "print(f\"Class weights: {class_weight_dict}\")\n",
    "print(f\"  Short (<24h): {class_weight_dict[0]:.3f}\")\n",
    "print(f\"  Long (≥24h): {class_weight_dict[1]:.3f}\")\n",
    "\n",
    "# ============================================================================\n",
    "# UNIFIED MODEL BUILDERS & TRAINING UTILITIES\n",
    "# ============================================================================\n",
    "\n",
    "def focal_loss(alpha=0.75, gamma=2.0):\n",
    "    \"\"\"Focal loss for imbalanced classification.\"\"\"\n",
    "    def loss_fn(y_true, y_pred):\n",
    "        y_true = tf.cast(y_true, tf.float32)\n",
    "        bce = keras.backend.binary_crossentropy(y_true, y_pred)\n",
    "        p_t = y_true * y_pred + (1 - y_true) * (1 - y_pred)\n",
    "        alpha_t = y_true * alpha + (1 - y_true) * (1 - alpha)\n",
    "        return tf.reduce_mean(alpha_t * tf.pow(1 - p_t, gamma) * bce)\n",
    "    return loss_fn\n",
    "\n",
    "def build_classification_model(version='v1', input_dim=22):\n",
    "    \"\"\"Build classification model with specified version.\"\"\"\n",
    "    configs = {\n",
    "        'v1': {'layers': [128, 64, 32], 'dropout': 0.3, 'l2': 0.001},\n",
    "        'v2': {'layers': [256, 128, 96, 64, 32], 'dropout': 0.2, 'l2': 0.0005},\n",
    "        'v3': {'layers': [256, 128, 64, 32], 'dropout': 0.2, 'l2': 0.0004},\n",
    "        'v4': {'layers': [256, 128, 64, 32, 16], 'dropout': 0.15, 'l2': 0.0003},\n",
    "    }\n",
    "    config = configs.get(version, configs['v1'])\n",
    "    \n",
    "    layers = [Dense(config['layers'][0], activation='relu', input_dim=input_dim,\n",
    "                    kernel_regularizer=regularizers.l2(config['l2'])),\n",
    "              BatchNormalization(), Dropout(config['dropout'])]\n",
    "    \n",
    "    for units in config['layers'][1:]:\n",
    "        layers.extend([\n",
    "            Dense(units, activation='relu', kernel_regularizer=regularizers.l2(config['l2'])),\n",
    "            BatchNormalization(),\n",
    "            Dropout(config['dropout'])\n",
    "        ])\n",
    "    \n",
    "    layers.append(Dense(1, activation='sigmoid'))\n",
    "    return Sequential(layers)\n",
    "\n",
    "def build_regression_model(version='v1', input_dim=22):\n",
    "    \"\"\"Build regression model with specified version.\"\"\"\n",
    "    configs = {\n",
    "        'v1': {'layers': [128, 64, 32, 16], 'dropout': 0.2, 'l2': 0.001},\n",
    "        'v2': {'layers': [256, 128, 64, 32, 16], 'dropout': 0.15, 'l2': 0.0005},\n",
    "        'v3': {'layers': [256, 128, 64, 32], 'dropout': 0.15, 'l2': 0.0004},\n",
    "    }\n",
    "    config = configs.get(version, configs['v1'])\n",
    "    \n",
    "    layers = [Dense(config['layers'][0], activation='relu', input_dim=input_dim,\n",
    "                    kernel_regularizer=regularizers.l2(config['l2'])),\n",
    "              BatchNormalization(), Dropout(config['dropout'])]\n",
    "    \n",
    "    for units in config['layers'][1:-1]:\n",
    "        layers.extend([\n",
    "            Dense(units, activation='relu', kernel_regularizer=regularizers.l2(config['l2'])),\n",
    "            BatchNormalization(),\n",
    "            Dropout(config['dropout'])\n",
    "        ])\n",
    "    \n",
    "    layers.append(Dense(config['layers'][-1], activation='relu'))\n",
    "    layers.append(Dense(1, activation='linear'))\n",
    "    return Sequential(layers)\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, version='v1',\n",
    "                task='classification', epochs=100, batch_size=64, \n",
    "                class_weights=None, loss_fn='binary_crossentropy'):\n",
    "    \"\"\"Unified model training function.\"\"\"\n",
    "    \n",
    "    # Compile\n",
    "    metrics = [tf.keras.metrics.AUC(name='auc')] if task == 'classification' else ['mae']\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001 if version != 'v4' else 0.0015),\n",
    "                  loss=loss_fn, metrics=metrics)\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stop = EarlyStopping(monitor='val_auc' if task == 'classification' else 'val_loss',\n",
    "                               mode='max' if task == 'classification' else 'min',\n",
    "                               patience=35 if version == 'v4' else 20,\n",
    "                               restore_best_weights=True, verbose=0)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_auc' if task == 'classification' else 'val_loss',\n",
    "                                  mode='max' if task == 'classification' else 'min',\n",
    "                                  factor=0.5 if version == 'v4' else 0.7,\n",
    "                                  patience=12 if version == 'v4' else 15,\n",
    "                                  min_lr=5e-5 if version == 'v4' else 1e-5, verbose=0)\n",
    "    \n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        validation_data=(X_test, y_test),\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        class_weight=class_weights,\n",
    "        callbacks=[early_stop, reduce_lr],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    return model, history\n",
    "\n",
    "def evaluate_classification(model, X_test, y_test, version='v1'):\n",
    "    \"\"\"Evaluate classification model and return metrics.\"\"\"\n",
    "    y_pred_proba = model.predict(X_test, verbose=0).flatten()\n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    \n",
    "    # Threshold optimization\n",
    "    best_f1, best_thr = -1, 0.5\n",
    "    best_prec, best_rec = 0, 0\n",
    "    \n",
    "    for threshold in np.linspace(0.2, 0.8, 60):\n",
    "        y_pred = (y_pred_proba >= threshold).astype(int)\n",
    "        prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='binary', zero_division=0)\n",
    "        if f1 > best_f1:\n",
    "            best_f1, best_thr = f1, threshold\n",
    "            best_prec, best_rec = prec, rec\n",
    "    \n",
    "    cm = confusion_matrix(y_test, (y_pred_proba >= best_thr).astype(int))\n",
    "    \n",
    "    return {\n",
    "        'version': version,\n",
    "        'auc': auc,\n",
    "        'threshold': best_thr,\n",
    "        'precision': best_prec,\n",
    "        'recall': best_rec,\n",
    "        'f1': best_f1,\n",
    "        'confusion_matrix': cm,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }\n",
    "\n",
    "def evaluate_regression(model, X_test, y_test, version='v1'):\n",
    "    \"\"\"Evaluate regression model and return metrics.\"\"\"\n",
    "    y_pred = model.predict(X_test, verbose=0).flatten()\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    return {\n",
    "        'version': version,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'r2': r2,\n",
    "        'y_pred': y_pred\n",
    "    }\n",
    "\n",
    "print(\"\\n✓ Unified model builders and training utilities loaded\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4679940b",
   "metadata": {},
   "source": [
    "### Running the NN Model(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f62ca26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      "TRAINING ALL CLASSIFICATION MODELS (V1, V2, V3, V4)\n",
      "===========================================================================\n",
      "\n",
      "▶ Training Classification V1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cyrils/Developer/Python/NeuralNetworks/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "2026-01-16 09:01:34.795612: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M4 Pro\n",
      "2026-01-16 09:01:34.795645: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 24.00 GB\n",
      "2026-01-16 09:01:34.795653: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 8.88 GB\n",
      "2026-01-16 09:01:34.795675: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2026-01-16 09:01:34.795687: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "2026-01-16 09:01:35.612984: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'precision_recall_fscore_support' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 49\u001b[39m\n\u001b[32m     38\u001b[39m history = model.fit(\n\u001b[32m     39\u001b[39m     X_train_scaled, y_train_cls,\n\u001b[32m     40\u001b[39m     validation_data=(X_test_scaled, y_test_cls),\n\u001b[32m   (...)\u001b[39m\u001b[32m     45\u001b[39m     verbose=\u001b[32m0\u001b[39m\n\u001b[32m     46\u001b[39m )\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m results = \u001b[43mevaluate_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m clf_results[version] = {\n\u001b[32m     51\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m'\u001b[39m: model,\n\u001b[32m     52\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mhistory\u001b[39m\u001b[33m'\u001b[39m: history,\n\u001b[32m     53\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m'\u001b[39m: results,\n\u001b[32m     54\u001b[39m     \u001b[33m'\u001b[39m\u001b[33my_pred_proba\u001b[39m\u001b[33m'\u001b[39m: results[\u001b[33m'\u001b[39m\u001b[33my_pred_proba\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     55\u001b[39m }\n\u001b[32m     57\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ✓ AUC=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33mauc\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | F1=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m @ θ=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults[\u001b[33m'\u001b[39m\u001b[33mthreshold\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 118\u001b[39m, in \u001b[36mevaluate_classification\u001b[39m\u001b[34m(model, X_test, y_test, version)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m threshold \u001b[38;5;129;01min\u001b[39;00m np.linspace(\u001b[32m0.2\u001b[39m, \u001b[32m0.8\u001b[39m, \u001b[32m60\u001b[39m):\n\u001b[32m    117\u001b[39m     y_pred = (y_pred_proba >= threshold).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     prec, rec, f1, _ = \u001b[43mprecision_recall_fscore_support\u001b[49m(y_test, y_pred, average=\u001b[33m'\u001b[39m\u001b[33mbinary\u001b[39m\u001b[33m'\u001b[39m, zero_division=\u001b[32m0\u001b[39m)\n\u001b[32m    119\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m f1 > best_f1:\n\u001b[32m    120\u001b[39m         best_f1, best_thr = f1, threshold\n",
      "\u001b[31mNameError\u001b[39m: name 'precision_recall_fscore_support' is not defined"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# OPTIMIZED: TRAIN ALL CLASSIFICATION MODELS IN ONE BATCH\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*75)\n",
    "print(\"TRAINING ALL CLASSIFICATION MODELS (V1, V2, V3, V4)\")\n",
    "print(\"=\"*75)\n",
    "\n",
    "# Dictionary to store all models and results\n",
    "clf_results = {}\n",
    "\n",
    "for version in ['v1', 'v2', 'v3', 'v4']:\n",
    "    print(f\"\\n▶ Training Classification {version.upper()}...\")\n",
    "    \n",
    "    # Build model\n",
    "    if version == 'v4':\n",
    "        # V4 uses focal loss\n",
    "        model = build_classification_model(version, X_train_scaled.shape[1])\n",
    "        model.compile(optimizer=Adam(learning_rate=0.0015),\n",
    "                      loss=focal_loss(alpha=0.8, gamma=2.0),\n",
    "                      metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "    else:\n",
    "        model = build_classification_model(version, X_train_scaled.shape[1])\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "    \n",
    "    # Configure callbacks\n",
    "    early_stop = EarlyStopping(monitor='val_auc', mode='max', \n",
    "                               patience=35 if version == 'v4' else 25,\n",
    "                               restore_best_weights=True, verbose=0)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_auc', mode='max',\n",
    "                                  factor=0.5 if version == 'v4' else 0.7,\n",
    "                                  patience=12 if version == 'v4' else 15,\n",
    "                                  min_lr=5e-5 if version == 'v4' else 1e-5, verbose=0)\n",
    "    \n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train_cls,\n",
    "        validation_data=(X_test_scaled, y_test_cls),\n",
    "        epochs=140 if version == 'v4' else 100,\n",
    "        batch_size=32 if version == 'v4' else 64,\n",
    "        class_weight=class_weight_dict,\n",
    "        callbacks=[early_stop, reduce_lr],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    results = evaluate_classification(model, X_test_scaled, y_test_cls, version)\n",
    "    clf_results[version] = {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'metrics': results,\n",
    "        'y_pred_proba': results['y_pred_proba']\n",
    "    }\n",
    "    \n",
    "    print(f\"  ✓ AUC={results['auc']:.4f} | F1={results['f1']:.3f} @ θ={results['threshold']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*75)\n",
    "print(\"CLASSIFICATION TRAINING COMPLETE\")\n",
    "print(\"=\"*75)\n",
    "\n",
    "# Extract for backward compatibility\n",
    "clf_model, history_cls, auc_nn, y_pred_proba_cls = (clf_results['v1']['model'], \n",
    "                                                      clf_results['v1']['history'],\n",
    "                                                      clf_results['v1']['metrics']['auc'],\n",
    "                                                      clf_results['v1']['y_pred_proba'])\n",
    "clf_model_v4, history_cls_v4 = clf_results['v4']['model'], clf_results['v4']['history']\n",
    "auc_nn_v4 = clf_results['v4']['metrics']['auc']\n",
    "y_pred_proba_cls_v4 = clf_results['v4']['y_pred_proba']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c81fc183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating unified classification comparison...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'v1'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mGenerating unified classification comparison...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Prepare comparison data\u001b[39;00m\n\u001b[32m      8\u001b[39m clf_comparison = pd.DataFrame([\n\u001b[32m      9\u001b[39m     {\n\u001b[32m     10\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mVersion\u001b[39m\u001b[33m'\u001b[39m: v.upper(),\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAUC\u001b[39m\u001b[33m'\u001b[39m: \u001b[43mclf_results\u001b[49m\u001b[43m[\u001b[49m\u001b[43mv\u001b[49m\u001b[43m]\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mauc\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     12\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mThreshold\u001b[39m\u001b[33m'\u001b[39m: clf_results[v][\u001b[33m'\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mthreshold\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     13\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mPrecision\u001b[39m\u001b[33m'\u001b[39m: clf_results[v][\u001b[33m'\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mprecision\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     14\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mRecall\u001b[39m\u001b[33m'\u001b[39m: clf_results[v][\u001b[33m'\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mrecall\u001b[39m\u001b[33m'\u001b[39m],\n\u001b[32m     15\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mF1 Score\u001b[39m\u001b[33m'\u001b[39m: clf_results[v][\u001b[33m'\u001b[39m\u001b[33mmetrics\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mf1\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     16\u001b[39m     }\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mv1\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mv2\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mv3\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mv4\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     18\u001b[39m ])\n\u001b[32m     20\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + clf_comparison.to_string(index=\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Save comparison\u001b[39;00m\n",
      "\u001b[31mKeyError\u001b[39m: 'v1'"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# OPTIMIZED: GENERATE UNIFIED CLASSIFICATION COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nGenerating unified classification comparison...\")\n",
    "\n",
    "# Prepare comparison data\n",
    "clf_comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Version': v.upper(),\n",
    "        'AUC': clf_results[v]['metrics']['auc'],\n",
    "        'Threshold': clf_results[v]['metrics']['threshold'],\n",
    "        'Precision': clf_results[v]['metrics']['precision'],\n",
    "        'Recall': clf_results[v]['metrics']['recall'],\n",
    "        'F1 Score': clf_results[v]['metrics']['f1']\n",
    "    }\n",
    "    for v in ['v1', 'v2', 'v3', 'v4']\n",
    "])\n",
    "\n",
    "print(\"\\n\" + clf_comparison.to_string(index=False))\n",
    "\n",
    "# Save comparison\n",
    "clf_comparison.to_csv('fig/classification/all_versions_comparison.csv', index=False)\n",
    "print(\"\\n✓ Saved comparison to fig/classification/all_versions_comparison.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6512b63b",
   "metadata": {},
   "source": [
    "## Conclusion for Classification models\n",
    "V4 focal-loss MLP demonstrates solid neural network optimization (+2.4% AUC over V1) through careful attention to:\n",
    "1. Loss function design (focal loss for recall)\n",
    "2. Regularization tuning (lighter L2/dropout)\n",
    "3. Architecture depth (5 layers > 3)\n",
    "4. Threshold optimization (0.473 for business objectives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149d6af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      "FEATURE ENGINEERING: Creating Enhanced Features for Regression\n",
      "===========================================================================\n",
      "\n",
      "V1 Regression Data:\n",
      "  Features: 20 (input_dim=20)\n",
      "  Training samples: 5049\n",
      "  Test samples: 1240\n",
      "\n",
      "V3 Regression Data:\n",
      "  Features: 26 (input_dim=26)\n",
      "  Training samples: 5049\n",
      "  Test samples: 1240\n",
      "\n",
      "===========================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3w/m5ggn48n0wqcwy2z2nbt8xn40000gn/T/ipykernel_20105/3663161304.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['hours_since_last_charge'].fillna(df['hours_since_last_charge'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# OPTIMIZED: ENHANCED FEATURE ENGINEERING (UNIFIED)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*75)\n",
    "print(\"FEATURE ENGINEERING: Creating Enhanced Features for Regression\")\n",
    "print(\"=\"*75)\n",
    "\n",
    "# Build base + enhanced feature sets\n",
    "feature_sets = {\n",
    "    'v1': feature_cols.copy(),  # Original features\n",
    "}\n",
    "\n",
    "# V3: Add energy-based features\n",
    "# Energy delivered (El_kWh) has significant impact on session duration\n",
    "feature_sets['v3'] = feature_cols.copy()\n",
    "feature_sets['v3'].append('El_kWh')\n",
    "\n",
    "# Create engineered features (computed once, reused for all versions)\n",
    "df_sorted_temp = df.sort_values(['User_ID', 'Start_plugin_dt'])\n",
    "df['hours_since_last_charge'] = (df_sorted_temp.groupby('User_ID')['Start_plugin_dt']\n",
    "                                   .diff().dt.total_seconds() / 3600)\n",
    "df['hours_since_last_charge'].fillna(df['hours_since_last_charge'].median(), inplace=True)\n",
    "\n",
    "df['temp_precip_interaction'] = df['temp_filled'] * df['precip_filled']\n",
    "df['user_energy_per_session'] = df['user_avg_energy'] / (df['user_session_count'] + 1)\n",
    "df['garage_user_ratio'] = df['garage_session_count'] / (df['user_session_count'] + 1)\n",
    "df['user_duration_cv'] = df['user_std_duration'] / (df['user_avg_duration'] + 0.1)\n",
    "\n",
    "feature_sets['v3'].extend(['hours_since_last_charge', 'temp_precip_interaction', \n",
    "                           'user_energy_per_session', 'garage_user_ratio', 'user_duration_cv'])\n",
    "\n",
    "# Prepare data for all regression versions\n",
    "reg_data = {}\n",
    "df_sorted = df.sort_values('Start_plugin_dt').reset_index(drop=True)\n",
    "split_idx_reg = int(len(df_sorted) * 0.8)\n",
    "\n",
    "for version in ['v1', 'v3']:\n",
    "    feature_set = feature_sets[version]\n",
    "    \n",
    "    train_df_temp = df_sorted.iloc[:split_idx_reg].copy()\n",
    "    test_df_temp = df_sorted.iloc[split_idx_reg:].copy()\n",
    "    \n",
    "    train_short = train_df_temp[train_df_temp['is_short_session'].astype(bool)]\n",
    "    test_short = test_df_temp[test_df_temp['is_short_session'].astype(bool)]\n",
    "    \n",
    "    X_train = train_short[feature_set].values\n",
    "    X_test = test_short[feature_set].values\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    y_train = train_short['Duration_hours'].values\n",
    "    y_test = test_short['Duration_hours'].values\n",
    "    \n",
    "    reg_data[version] = {\n",
    "        'X_train': X_train_scaled,\n",
    "        'X_test': X_test_scaled,\n",
    "        'y_train': y_train,\n",
    "        'y_test': y_test,\n",
    "        'input_dim': len(feature_set),\n",
    "        'n_train': len(y_train),\n",
    "        'n_test': len(y_test)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{version.upper()} Regression Data:\")\n",
    "    print(f\"  Features: {len(feature_set)} (input_dim={reg_data[version]['input_dim']})\")\n",
    "    print(f\"  Training samples: {reg_data[version]['n_train']}\")\n",
    "    print(f\"  Test samples: {reg_data[version]['n_test']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "abd41ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===========================================================================\n",
      "TRAINING ALL REGRESSION MODELS (V1, V3)\n",
      "===========================================================================\n",
      "\n",
      "▶ Training Regression V1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cyrils/Developer/Python/NeuralNetworks/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ RMSE=5.688h | MAE=4.351h | R²=0.2422\n",
      "\n",
      "▶ Training Regression V3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cyrils/Developer/Python/NeuralNetworks/.venv/lib/python3.12/site-packages/keras/src/layers/core/dense.py:106: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ✓ RMSE=5.207h | MAE=3.936h | R²=0.3649\n",
      "\n",
      "===========================================================================\n",
      "REGRESSION TRAINING COMPLETE\n",
      "===========================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# OPTIMIZED: TRAIN ALL REGRESSION MODELS IN ONE BATCH\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*75)\n",
    "print(\"TRAINING ALL REGRESSION MODELS (V1, V3)\")\n",
    "print(\"=\"*75)\n",
    "\n",
    "reg_results = {}\n",
    "\n",
    "for version in ['v1', 'v3']:\n",
    "    print(f\"\\n▶ Training Regression {version.upper()}...\")\n",
    "    \n",
    "    data = reg_data[version]\n",
    "    \n",
    "    # Build model\n",
    "    model = build_regression_model(version, input_dim=data['input_dim'])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='mse', metrics=['mae', tf.keras.metrics.RootMeanSquaredError(name='rmse')])\n",
    "    \n",
    "    # Callbacks\n",
    "    early_stop = EarlyStopping(monitor='val_rmse', mode='min', patience=35,\n",
    "                               restore_best_weights=True, verbose=0)\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_rmse', mode='min', factor=0.7,\n",
    "                                  patience=20, min_lr=1e-5, verbose=0)\n",
    "    \n",
    "    # Train\n",
    "    history = model.fit(\n",
    "        data['X_train'], data['y_train'],\n",
    "        validation_data=(data['X_test'], data['y_test']),\n",
    "        epochs=200,\n",
    "        batch_size=32,\n",
    "        callbacks=[early_stop, reduce_lr],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    results = evaluate_regression(model, data['X_test'], data['y_test'], version)\n",
    "    reg_results[version] = {\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'metrics': results,\n",
    "        'y_pred': results['y_pred']\n",
    "    }\n",
    "    \n",
    "    print(f\"  ✓ RMSE={results['rmse']:.3f}h | MAE={results['mae']:.3f}h | R²={results['r2']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*75)\n",
    "print(\"REGRESSION TRAINING COMPLETE\")\n",
    "print(\"=\"*75)\n",
    "\n",
    "# Extract for backward compatibility\n",
    "reg_model, history_reg = reg_results['v1']['model'], reg_results['v1']['history']\n",
    "rmse_nn, mae_nn, r2_nn = (reg_results['v1']['metrics']['rmse'],\n",
    "                          reg_results['v1']['metrics']['mae'],\n",
    "                          reg_results['v1']['metrics']['r2'])\n",
    "reg_model_v3, history_reg_v3 = reg_results['v3']['model'], reg_results['v3']['history']\n",
    "rmse_nn_v3, mae_nn_v3, r2_nn_v3 = (reg_results['v3']['metrics']['rmse'],\n",
    "                                     reg_results['v3']['metrics']['mae'],\n",
    "                                     reg_results['v3']['metrics']['r2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "60074e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating unified regression comparison...\n",
      "\n",
      "      Version  RMSE (hours)  MAE (hours)  R² Score\n",
      "           V1      5.688107     4.351168  0.242178\n",
      "           V3      5.207124     3.936169  0.364921\n",
      "BASELINE (RF)      5.950000     4.190000  0.161000\n",
      "\n",
      "✓ Saved comparison to fig/modeling_regularized/all_regression_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# OPTIMIZED: UNIFIED REGRESSION COMPARISON\n",
    "# ============================================================================\n",
    "\n",
    "print(\"\\nGenerating unified regression comparison...\")\n",
    "\n",
    "# Prepare comparison\n",
    "reg_comparison = pd.DataFrame([\n",
    "    {\n",
    "        'Version': v.upper(),\n",
    "        'RMSE (hours)': reg_results[v]['metrics']['rmse'],\n",
    "        'MAE (hours)': reg_results[v]['metrics']['mae'],\n",
    "        'R² Score': reg_results[v]['metrics']['r2']\n",
    "    }\n",
    "    for v in ['v1', 'v3']\n",
    "])\n",
    "reg_comparison = pd.concat([reg_comparison, pd.DataFrame([\n",
    "    {'Version': 'BASELINE (RF)', 'RMSE (hours)': 5.95, 'MAE (hours)': 4.19, 'R² Score': 0.1610}\n",
    "])], ignore_index=True)\n",
    "\n",
    "print(\"\\n\" + reg_comparison.to_string(index=False))\n",
    "\n",
    "reg_comparison.to_csv('fig/modeling_regularized/all_regression_comparison.csv', index=False)\n",
    "print(\"\\n✓ Saved comparison to fig/modeling_regularized/all_regression_comparison.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
